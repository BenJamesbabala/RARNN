{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "USE_CUDA = False\n",
    "SHOW_ATTENTION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nalgene.generate import *\n",
    "\n",
    "parsed = parse_file('.', 'grammar.nlg')\n",
    "parsed.map_leaves(tokenizeLeaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors from ../pytorch-seq2seq-intent-parsing/data/glove.twitter.27B.100d.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import load_word_vectors\n",
    "\n",
    "def tokenize_sentence(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'(\\d)', r'\\1 ', s)\n",
    "    s = re.sub(r'[^a-z0-9 \\']', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s.split(' ')\n",
    "\n",
    "class GloVeLang:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        base_dir = '../pytorch-seq2seq-intent-parsing/data/'\n",
    "        glove_dict, glove_arr, glove_size = load_word_vectors(base_dir, 'glove.twitter.27B', size)\n",
    "        self.glove_dict = glove_dict\n",
    "        self.glove_arr = glove_arr\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s(size = %d)\" % (self.__class__.__name__, self.size)\n",
    "\n",
    "    def vector_from_word(self, word):\n",
    "        if word in self.glove_dict:\n",
    "            return self.glove_arr[self.glove_dict[word]]\n",
    "        else:\n",
    "            return torch.zeros(self.size)\n",
    "\n",
    "    def tokens_to_tensor(self, words):\n",
    "        tensor = torch.zeros(len(words), 1, self.size)\n",
    "        for wi in range(len(words)):\n",
    "            word = words[wi]\n",
    "            tensor[wi][0] = self.vector_from_word(word)\n",
    "        return tensor\n",
    "\n",
    "input_lang = GloVeLang(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descend(node, fn, child_type='phrase', returns=None):\n",
    "    if returns is None: returns = []\n",
    "    returned = fn(node)\n",
    "    returns.append(returned)\n",
    "\n",
    "    for child in node.children:\n",
    "        if (child_type is None) or (child.type == child_type):\n",
    "            descend(child, fn, child_type, returns)\n",
    "    \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ascend(node, fn):\n",
    "    if node.parent is None:\n",
    "        return fn(node)\n",
    "    else:\n",
    "        return ascend(node.parent, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building input and output vocabularies\n",
    "\n",
    "To find all input vocabulary tokens, we can traverse the parsed nalgene tree and copy all `word` type tokens.\n",
    "\n",
    "**TODO**: Use GloVe vectors for input vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input_tokens = []\n",
    "\n",
    "# def get_input_tokens(node):\n",
    "#     if node.type == 'word':\n",
    "#         input_tokens.append(node.key)\n",
    "\n",
    "# descend(parsed, get_input_tokens, None)\n",
    "\n",
    "# input_tokens = list(set(input_tokens))\n",
    "# input_tokens = ['EOS'] + input_tokens\n",
    "# print(input_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For output tokens, we can just take the top level node names that are either phrases or variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EOS', '%', '%main', '%if', '%timer', '%alarm', '%reminder', '%sequence', '%time', '%relative_time', '%absolute_time', '%condition', '%compare', '%getValue', '%action', '%alert', '%message', '%message_type', '@sms', '@email', '@call', '@chat', '%getLightState', '%getSwitchState', '%getTemperature', '%getPrice', '%setLightState', '%setSwitchState', '%setTemperature', '%setVolume', '%playMusic', '%greeting', '%thanks', '$message', '%operator', '@equal', '@greater_than', '@less_than', '%asset', '@btc', '@eth', '$stock', '%room_name', '@office', '@living_room', '@bedroom', '@basement', '@kitchen', '@bathroom', '@outside', '%light_name', '@office_light', '@living_room_light', '@bedroom_light', '@basement_light', '@kitchen_light', '@bathroom_light', '@outside_light', '%switch_name', '@tea_switch', '@coffee_switch', '%light_state', '%switch_state', '%volume_state', '@on', '@off', '@up', '@down', '@high', '@low', '$color', '$number', '$digits', '$digit', '%time_unit', '@seconds', '@minutes', '@hours', '@days', '$temperature', '$time', '$hour', '$minute', '$artist_name', '$song_name']\n"
     ]
    }
   ],
   "source": [
    "output_tokens = [child.key for child in parsed.children if child.type in ['phrase', 'ref', 'value']]\n",
    "output_tokens = ['EOS'] + output_tokens\n",
    "print(output_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting input and target data for nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words_for_position(words, position):\n",
    "    if position is None:\n",
    "        return words\n",
    "    start, end, length = position\n",
    "    return words[start : end + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def relative_position(node, parent):\n",
    "    if parent.position is None:\n",
    "        return node.position\n",
    "    return node.position[0] - parent.position[0], node.position[1] - parent.position[0], node.position[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_for_node(flat, node):\n",
    "    words = [child.key for child in flat.children]\n",
    "    inputs = words_for_position(words, node.position)\n",
    "    keys = [child.key for child in node.children]\n",
    "    positions = [relative_position(child, node) for child in node.children]\n",
    "    return node.key, inputs, list(zip(keys, positions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tensors for input and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_tensor(tokens, source_tokens, append_eos=True):\n",
    "    indexes = []\n",
    "    for token in tokens:\n",
    "        indexes.append(source_tokens.index(token))\n",
    "    if append_eos:\n",
    "        indexes.append(0)\n",
    "    return torch.LongTensor(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ranges_to_tensor(ranges, seq_len):\n",
    "    ranges_tensor = torch.zeros(len(ranges), seq_len)\n",
    "    for r in range(len(ranges)):\n",
    "        start, end, _ = ranges[r]\n",
    "        ranges_tensor[r, start:end+1] = 1\n",
    "    return ranges_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The core model is a regular seq2seq/encoder-decoder model with attention. The attention model is from [Luong et al.'s \"Effective Approaches to Attention-based Neural Machine Translation\"](https://arxiv.org/abs/1508.04025) using dot-product based attention energies, with one important difference: there is no softmax layer, allowing attention to focus on multiple tokens at once. Instead a sigmoid layer is added to squeeze outputs between 0 and 1.\n",
    "\n",
    "The encoder and decoder take one additional input `context` which represents the type of phrase, e.g. `%setLightState`. At the top level node the context is always `%`.\n",
    "\n",
    "The encoder encodes the input sequence into a series of vectors using a bidirectional GRU. The decoder \"translates\" this into a sequence of phrase tokens, given the encoder outputs and current context, e.g. \"turn off the office light\" + `%setLightState` &rarr; `[$on_off, $light]`.\n",
    "\n",
    "Once the decoder has chosen tokens and alignments, the phrase tokens and selection of inputs are used as the context and inputs of the next iteration. This recurs until no more phrase tokens are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.05):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, context_input, word_inputs):\n",
    "        # TODO: Incorporate context input\n",
    "        # TODO: Batching\n",
    "        \n",
    "        seq_len = word_inputs.size(0)\n",
    "        batch_size = word_inputs.size(1)\n",
    "        \n",
    "        embedded = self.embedding(word_inputs.view(seq_len * batch_size, -1)) # Process seq x batch at once\n",
    "        output = embedded.view(seq_len, batch_size, -1) # Resize back to seq x batch for RNN\n",
    "\n",
    "        outputs, hidden = self.gru(output)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attention_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
    "        if USE_CUDA: attention_energies = attention_energies.cuda()\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attention_energies[i] = hidden.dot(encoder_outputs[i])\n",
    "\n",
    "        # Squeeze to range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.sigmoid(attention_energies).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout=0.05):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Attention module\n",
    "        self.attention = Attention()\n",
    "    \n",
    "    def forward(self, context_input, word_input, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        # TODO: Batching\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        \n",
    "        # Combine context and embedded word, through RNN\n",
    "        rnn_input = torch.cat((context_input.unsqueeze(0), word_embedded), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "        attention_weights = self.attention(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attention_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn the whole thing into one module by combining the Encoder and Decoder networks. There's also an embedding layer for the context tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "\n",
    "class RARNN(nn.Module):\n",
    "    def __init__(self, input_size, output_tokens, hidden_size):\n",
    "        super(RARNN, self).__init__()\n",
    "        \n",
    "        self.output_tokens = output_tokens\n",
    "        self.input_size = input_size\n",
    "        self.output_size = len(output_tokens)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, hidden_size)\n",
    "        \n",
    "        self.encoder = Encoder(self.input_size, hidden_size)\n",
    "        self.decoder = Decoder(hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, context_input, word_inputs, word_targets=None):\n",
    "        # Get embedding for context input\n",
    "        context_embedded = self.embedding(context_input)\n",
    "        \n",
    "        input_len = word_inputs.size(0)\n",
    "        target_len = word_targets.size(0) if word_targets is not None else MAX_LENGTH\n",
    "        \n",
    "        # Run through encoder\n",
    "        encoder_outputs, encoder_hidden = self.encoder(context_embedded, word_inputs)\n",
    "        decoder_hidden = encoder_hidden # Use encoder's last hidden state\n",
    "        decoder_input = Variable(torch.LongTensor([0])) # EOS/SOS token\n",
    "        if USE_CUDA:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "\n",
    "        # Variables to store decoder and attention outputs\n",
    "        decoder_outputs = Variable(torch.zeros(target_len, self.output_size))\n",
    "        decoder_attentions = Variable(torch.zeros(target_len, input_len))\n",
    "        if USE_CUDA:\n",
    "            decoder_outputs = decoder_outputs.cuda()\n",
    "            decoder_attentions = decoder_attentions.cuda()\n",
    "        \n",
    "        # Run through decoder\n",
    "        for i in range(target_len):\n",
    "            decoder_output, decoder_hidden, decoder_attention = self.decoder(context_embedded, decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_outputs[i] = decoder_output\n",
    "            decoder_attentions[i] = decoder_attention\n",
    "\n",
    "            # Teacher forcing with known targets, if provided\n",
    "            if word_targets is not None:\n",
    "                decoder_input = word_targets[i]\n",
    "\n",
    "            # Sample with last outputs\n",
    "            else:\n",
    "                max_index = decoder_output.topk(1)[1].data[0][0]\n",
    "                decoder_input = Variable(torch.LongTensor([max_index]))\n",
    "                if USE_CUDA:\n",
    "                    decoder_input = decoder_input.cuda()\n",
    "\n",
    "                if max_index == 0: break # EOS\n",
    "        \n",
    "        # Slice outputs\n",
    "        if word_targets is None:\n",
    "            if i > 0:\n",
    "                decoder_outputs = decoder_outputs[:i]\n",
    "                decoder_attentions = decoder_attentions[:i]\n",
    "            else:\n",
    "                decoder_outputs = Variable(torch.Tensor())\n",
    "                decoder_attentions = Variable(torch.Tensor())\n",
    "\n",
    "        elif target_len > 1:\n",
    "            decoder_attentions = decoder_attentions[:-1] # Ignore attentions on EOS\n",
    "\n",
    "        return decoder_outputs, decoder_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The inputs to the network are the current phrase label, e.g. `%getLightState` and the string to parse, \"the living room light is on\". The outputs are the child node labels, `$light` and `$on_off` with a selection of words given by attention-like weights over the sequence, treated as boolean values given a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "hidden_size = 100\n",
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-6\n",
    "\n",
    "rarnn = RARNN(input_size, output_tokens, hidden_size)\n",
    "optimizer = torch.optim.Adam(rarnn.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "decoder_criterion = nn.NLLLoss()\n",
    "attention_criterion = nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(flat, node):\n",
    "    context, inputs, targets = data_for_node(flat, node)\n",
    "\n",
    "    # Turn inputs into tensors\n",
    "    context_var = tokens_to_tensor([context], rarnn.output_tokens, False)\n",
    "    context_var = Variable(context_var)\n",
    "    inputs_var = input_lang.tokens_to_tensor(inputs) # seq x batch x size\n",
    "    inputs_var = Variable(inputs_var)\n",
    "    target_tokens = [target_token for target_token, _ in targets]\n",
    "    target_ranges = [target_range for _, target_range in targets]\n",
    "    target_tokens_var = tokens_to_tensor(target_tokens, rarnn.output_tokens)\n",
    "    target_tokens_var = Variable(target_tokens_var)\n",
    "    target_ranges_var = ranges_to_tensor(target_ranges, len(inputs))\n",
    "    target_ranges_var = Variable(target_ranges_var)\n",
    " \n",
    "    # Run through model\n",
    "    decoder_outputs, attention_outputs = rarnn(context_var, inputs_var, target_tokens_var)\n",
    "\n",
    "    # Loss calculation and backprop\n",
    "    optimizer.zero_grad()\n",
    "    decoder_loss = decoder_criterion(decoder_outputs, target_tokens_var)\n",
    "    if len(targets) > 0:\n",
    "        attention_loss = attention_criterion(attention_outputs, target_ranges_var)\n",
    "    else:\n",
    "        attention_loss = 0\n",
    "    total_loss = decoder_loss + attention_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return total_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job 5945d97ef8e1c2083c22e0b1 at 2017-06-17 18:38:06\n",
      "[log] 0m 8s (100) 4.3188\n",
      "[log] 0m 18s (200) 1.0373\n",
      "[log] 0m 27s (300) 0.7562\n",
      "[log] 0m 35s (400) 3.1305\n",
      "[log] 0m 45s (500) 0.3602\n",
      "[log] 0m 54s (600) 0.4813\n",
      "[log] 1m 5s (700) 0.3830\n",
      "[log] 1m 14s (800) 0.1757\n",
      "[log] 1m 25s (900) 1.9926\n",
      "[log] 1m 35s (1000) 1.6087\n",
      "[log] 1m 46s (1100) 0.1349\n",
      "[log] 1m 54s (1200) 0.1791\n",
      "[log] 2m 4s (1300) 0.0779\n",
      "[log] 2m 16s (1400) 0.1250\n",
      "[log] 2m 27s (1500) 0.1004\n",
      "[log] 2m 38s (1600) 0.0730\n",
      "[log] 2m 49s (1700) 0.0762\n",
      "[log] 2m 59s (1800) 0.0403\n",
      "[log] 3m 10s (1900) 0.0182\n",
      "[log] 3m 22s (2000) 0.0059\n",
      "[log] 3m 34s (2100) 0.0430\n",
      "[log] 3m 45s (2200) 0.0731\n",
      "[log] 3m 55s (2300) 0.0526\n",
      "[log] 4m 4s (2400) 0.0451\n",
      "[log] 4m 14s (2500) 0.0235\n",
      "[log] 4m 22s (2600) 0.0061\n",
      "[log] 4m 33s (2700) 0.3634\n",
      "[log] 4m 45s (2800) 0.2099\n",
      "[log] 4m 55s (2900) 0.0206\n",
      "[log] 5m 6s (3000) 0.0111\n",
      "[log] 5m 15s (3100) 0.0018\n",
      "[log] 5m 26s (3200) 0.4094\n",
      "[log] 5m 40s (3300) 0.5237\n",
      "[log] 5m 49s (3400) 0.0044\n",
      "[log] 6m 1s (3500) 0.0179\n",
      "[log] 6m 13s (3600) 0.5085\n",
      "[log] 6m 22s (3700) 0.0081\n",
      "[log] 6m 32s (3800) 0.0218\n",
      "[log] 6m 44s (3900) 0.5667\n",
      "[log] 6m 55s (4000) 0.0011\n",
      "[log] 7m 5s (4100) 0.6060\n",
      "[log] 7m 15s (4200) 0.0236\n",
      "[log] 7m 26s (4300) 0.2471\n",
      "[log] 7m 34s (4400) 0.0008\n",
      "[log] 7m 43s (4500) 0.3001\n",
      "[log] 7m 56s (4600) 0.0012\n",
      "[log] 8m 6s (4700) 0.4515\n",
      "[log] 8m 18s (4800) 0.0030\n",
      "[log] 8m 29s (4900) 0.0006\n"
     ]
    }
   ],
   "source": [
    "import sconce\n",
    "job = sconce.Job('rarnn')\n",
    "job.plot_every = 20\n",
    "job.log_every = 100\n",
    "\n",
    "n_epochs = 5000\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    walked_flat, walked_tree = walk_tree(parsed, parsed['%'], None)\n",
    "    def _train(node): return train(walked_flat, node)\n",
    "    ds = descend(walked_tree, _train)\n",
    "    d = sum(ds) / len(ds)\n",
    "    job.record(i, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(context, inputs, node=None):\n",
    "    if node == None:\n",
    "        node = Node('parsed')\n",
    "        node.position = (0, len(inputs))\n",
    "    \n",
    "    # Turn data into tensors\n",
    "    context_var = tokens_to_tensor([context], rarnn.output_tokens, False)\n",
    "    context_var = Variable(context_var)\n",
    "    inputs_var = input_lang.tokens_to_tensor(inputs) # seq x batch x size\n",
    "    inputs_var = Variable(inputs_var)\n",
    "    \n",
    "    # Run through RARNN\n",
    "    decoder_outputs, attention_outputs = rarnn(context_var, inputs_var)\n",
    "    \n",
    "    # Given the decoder and attention outputs, gather contexts and inputs for sub-phrases\n",
    "    # Use attention values > 0.5 to select words for next input sequence\n",
    "\n",
    "    next_contexts = []\n",
    "    next_inputs = []\n",
    "    next_positions = []\n",
    "    \n",
    "    for i in range(len(decoder_outputs)):\n",
    "        max_value, max_index = decoder_outputs[i].topk(1)\n",
    "        max_index = max_index.data[0]\n",
    "        next_contexts.append(rarnn.output_tokens[max_index]) # Get decoder output token\n",
    "        a = attention_outputs[i]\n",
    "        next_input = []\n",
    "        next_position = []\n",
    "        for t in range(len(a)):\n",
    "            at = a[t].data[0]\n",
    "            if at > 0.5:\n",
    "                if len(next_position) == 0: # Start position\n",
    "                    next_position.append(t)\n",
    "                next_input.append(inputs[t])\n",
    "            else:\n",
    "                if len(next_position) == 1: # End position\n",
    "                    next_position.append(t - 1)\n",
    "        if len(next_position) == 1: # End position\n",
    "            next_position.append(t)\n",
    "        next_inputs.append(next_input)\n",
    "        if len(next_position) == 2:\n",
    "            next_position = (next_position[0] + node.position[0], next_position[1] + node.position[0])\n",
    "        next_positions.append(next_position)\n",
    "\n",
    "    evaluated = list(zip(next_contexts, next_inputs, next_positions))\n",
    "\n",
    "    # Print decoded outputs\n",
    "    print('\\n(evaluate) %s %s -> %s' % (context, ' '.join(inputs), next_contexts))\n",
    "    \n",
    "    # Plot attention outputs\n",
    "    if SHOW_ATTENTION:\n",
    "        if len(attention_outputs) > 1:\n",
    "            print(attention_outputs)\n",
    "            fig = plt.figure(figsize=(len(inputs) / 3, 99))\n",
    "            sub = fig.add_subplot(111)\n",
    "            sub.matshow(attention_outputs.data.squeeze(1).numpy(), vmin=0, vmax=1, cmap='hot')\n",
    "            plt.show(); plt.close()\n",
    "        else:\n",
    "            print(\"WARNING: No attention outputs\")\n",
    "    \n",
    "    for context, inputs, position in evaluated:\n",
    "        # Add a node for parsed sub-phrases and values\n",
    "        sub_node = Node(context)\n",
    "        sub_node.position = position\n",
    "        node.add(sub_node)\n",
    "        \n",
    "        # Recursively evaluate sub-phrases\n",
    "        if context[0] == '%':\n",
    "            if len(inputs) > 0:\n",
    "                evaluate(context, inputs, sub_node)\n",
    "            else:\n",
    "                print(\"WARNING: Empty inputs\")\n",
    "    \n",
    "        # Or add words directly to value node\n",
    "        elif context[0] == '$':\n",
    "            sub_node.add(' '.join(inputs))\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_and_print(context, inputs):\n",
    "    evaluated = evaluate(context, inputs)\n",
    "    print(' '.join(inputs))\n",
    "    print(evaluated)\n",
    "    return evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) % hey maia what's the btc price -> ['%sequence']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %sequence maia what's the btc price -> ['%action']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %action maia what's the btc price -> ['%getPrice']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %getPrice maia what's the btc price -> ['%asset']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %asset maia btc -> ['@btc']\n",
      "WARNING: No attention outputs\n",
      "hey maia what's the btc price\n",
      "( parsed (0, 6)\n",
      "    ( %sequence (1, 5)\n",
      "        ( %action (1, 5)\n",
      "            ( %getPrice (1, 5)\n",
      "                ( %asset (1, 1)\n",
      "                    ( @btc (1, 2) ) ) ) ) ) )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nalgene.node.Node at 0x134047438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_and_print('%', \"hey maia what's the btc price\".split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) % plz call me when the price of tesla is above 5 0 -> ['%if']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %if plz call me when the price of tesla is above 5 0 -> ['%alert', '%condition']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.9992  0.9949  0.9812  0.0012  0.0730  0.0121  0.0106  0.0107  0.0003  0.0030\n",
      " 0.0038  0.0185  0.0439  0.0057  0.9385  0.9858  0.9972  0.9987  0.9992  0.9999\n",
      "\n",
      "Columns 10 to 11 \n",
      " 0.0107  0.0043\n",
      " 0.9996  0.9996\n",
      "[torch.FloatTensor of size 2x12]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAABICAYAAADWBUg5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABZpJREFUeJzt3V2IVHUcxvHv027hG1SyS5RK40UUEpWxhCVEVBdGkV1F\nQSEheNOLRRDWTbddRNRFBIuZQmKEBUlEL1hQFxFNKeRLUlTm+pIjUpYQav26mGMsa9MctzPnf+j/\nfG525uzwPw+z88x52TP/UURgZnk5J3UAM6ufi2+WIRffLEMuvlmGXHyzDLn4ZhmqvfiSlknaI+lb\nSWvqXv8/kbRA0keSdknaKWl16kynSRqStE3S26mzAEi6QNJmSV9L2i3p+gZkeqz4u+2QtEnSjEQ5\n1kk6LGnHpGVzJX0g6Zvi54Upsk1Va/ElDQEvArcBi4B7JS2qM0MPp4DHI2IRsAR4sCG5AFYDu1OH\nmOQF4N2IuAK4msTZJM0DHgHGIuJKYAi4J1Gc9cCyKcvWAFsj4jJga3E/ubq3+NcB30bEdxFxAngN\nWF5zhjNExMGI+LK4/SvdF/O8tKlA0nzgdmBt6iwAks4HbgReBoiIExHxc9pUAAwDMyUNA7OAAylC\nRMTHwNEpi5cDG4rbG4C7ag3VQ93Fnwfsm3R/ggYUbDJJLWAx8FnaJAA8DzwB/Jk6SGEh0AFeKQ4/\n1kqanTJQROwHngV+BA4Cv0TE+ykzTXFRRBwsbh8CLkoZ5jSf3JtE0hzgDeDRiDiWOMsdwOGI+CJl\njimGgWuBlyJiMXCcxLuuxTHzcrpvSpcAsyXdlzJTL9G9Pr4R18jXXfz9wIJJ9+cXy5KTdC7d0m+M\niDdT5wGWAndK+oHuIdHNkl5NG4kJYCIiTu8Nbab7RpDSrcD3EdGJiJPAm8ANiTNN9pOkiwGKn4cT\n5wHqL/7nwGWSFko6j+5JmC01ZziDJNE9bt0dEc+lzgMQEU9GxPyIaNF9nj6MiKRbsog4BOyTdHmx\n6BZgV8JI0N3FXyJpVvF3vIVmnQzdAqwobq8A3kqY5W/Dda4sIk5Jegh4j+7Z13URsbPODD0sBe4H\nvpK0vVj2VES8kzBTUz0MbCzeuL8DHkgZJiI+k7QZ+JLuf2e2AeMpskjaBNwEjEiaAJ4GngFel7QS\n2AvcnSLbVPLHcs3y45N7Zhly8c0y5OKbZcjFN8uQi2+WoWTFl7Qq1bp7caZympgJmpmriZkg7Ra/\niU+IM5XTxEzQzFxNzORdfbMcDeQCnpGRkWi1Wv/6mE6nw+joaInRqsrX/wNunc4RRkdH+j5u2xfb\n+z6mrJl9fn8SOLfEOL9XkKWsP6l/i1HmVRCABh1kin7rK/tcVfkqj4i+T8NALtlttVq02+2KRjtV\n0Ti/VTQOzK5wEpWrKhpnT0XjAPxR4VhVOZk6QA9l3pTLqOpz18dLPs67+mYZcvHNMuTim2WoVPGb\nODOumU1f3+I3eGZcM5umMlv8Rs6Ma2bTV6b4jZ8Z18zOTmUn9yStktSW1O50OlUNa2YDUKb4pWbG\njYjxiBiLiLFyV+SZWSplit/ImXHNbPr6XrLb4JlxzWyaSl2rX0wz7ammzf4nfOWeWYZcfLMMufhm\nGXLxzTI0kBl4hqSYUdFYVX35+tyKxgE4UOFYx+KTika6pqJxAOZUOJbVaWxsjHa73XcGHm/xzTLk\n4ptlyMU3y5CLb5YhF98sQ2Vm4Fkn6bCkHXUEMrPBK7PFXw8sG3AOM6tR3+JHxMfA0RqymFlNfIxv\nlqHKvkKr+DrgVVD/95eZ2dmprPgRMQ6MQ/eS3arGNbPqeVffLENl/p23CfgUuFzShKSVg49lZoNU\nZs69e+sIYmb18a6+WYZcfLMMufhmGXLxzTI0kKm3JHWAvX0eNgIcqXzl/40zldPETNDMXHVnujQi\n+n6H3UCKX4akdkSMJVl5D85UThMzQTNzNTETeFffLEsuvlmGUhZ/POG6e3GmcpqYCZqZq4mZ0h3j\nm1k63tU3y5CLb5YhF98sQy6+WYZcfLMM/QXre4niwlfm+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133878eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %alert plz call me -> ['%message_type']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %message_type call -> ['@call']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %condition the price of tesla is above 5 0 -> ['%getValue', '$number']\n",
      "Variable containing:\n",
      " 0.9993  0.9997  0.9956  0.9776  0.1356  0.2025  0.0101  0.0017\n",
      " 0.0001  0.0009  0.0021  0.0003  0.0313  0.9805  0.7363  0.7212\n",
      "[torch.FloatTensor of size 2x8]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAABICAYAAABfnd9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABWBJREFUeJzt3d+LVGUcx/H3p21FWUWlnYtwxTEIQSpUFikSCaVQC7tV\n6E7Zm4KkiyiCon8guolgMSuoNsh+ECJEkdBNVLPq1vqj0FhxTdvRClOK9ce3i3MWlgrnzHOeMzs8\nfF9w2DO7Zz/zndnvnH3mnHlmZGY4l4rb5roA52LyhnZJ8YZ2SfGGdknxhnZJ8YZ2Sel4Q0vaIulH\nSackPVciZ5+kKUnjEWpaLumQpOOSjkl6OjBnvqRvJY3lOS9HqK1H0hFJB0pkTEj6QdJRSY2S9SyR\ntF/SSUknJD0QmLMqr2dmuSxpT5naADCzji1AD3AauAuYB4wBqwOzNgLrgPEIdd0JrMvXFwE/hdQF\nCFiYr/cC3wD3l6ztGeA94ECJjAmgP9Lf8G1gd74+D1gSqS8uACvKZnV6D70eOGVmP5vZNPA+8HhI\nkJl9BfwWoygzO29mh/P1P4ETwLKAHDOzK/nF3nwJPnMlaQB4FNgbmhGTpMVkO5I3AMxs2sz+iBC9\nGThtZmfKBnW6oZcBZ2ddniSgcaokqQ6sJdu7hvx+j6SjwBTwuZkF5eReBZ4FbpbIgOxB9YWkUUlD\nJXJWAk3gzXwYtFdSX8naAHYAIxFy/EnhbJIWAh8Ce8zsckiGmd0wszXAALBe0j2BtTwGTJnZaMjv\n/8uGvKatwJOSNgbm3E42zHvdzNYCV4Hg50EAkuYB24EPyuTM6HRDnwOWz7o8kH9vzknqJWvmd83s\no7J5+b/iQ8CWwIgHge2SJsiGZpskvRNYy7n86xTwMdnQL8QkMDnrv85+sgYvYytw2Mx+LZkDdL6h\nvwPulrQyf2TuAD7tcA3/IUlk48ITZvZKiZyapCX5+gLgYeBkSJaZPW9mA2ZWJ7ufvjSzJwJq6pO0\naGYdeAQIOjJkZheAs5JW5d/aDBwPyZplJ5GGG0Bnj3Lkz2i3kR1FOA28UCJnBDgPXCPbc+wqkbWB\nbJz5PXA0X7YF5NwHHMlzxoEXI91nDxF4lIPsiNJYvhwrc5/neWuARn4bPwGWlsjqAy4Bi2P1l/Jg\n55LgTwpdUryhXVK8oV1SvKFdUryhXVLmrKFLnoKNntOtWV5Te+ZyDx3rhsS8Q7oxy2tqgw85XFIq\nObHS399v9Xr9lts0m01qtVrp6yqe0/p2NpsXqdX6C2TdKJB1iVrtjltuc2Z0rGXOX8CCAhUV2eYK\nsLDAdr+0+PlNiu0Ji3SWkb2IvNX1mVmrzYDs1VPR1et1Go1SEyMqcD1iVoyXAMNulX9Az7g3WhK8\nFCnnWqScv9vY1occLine0C4p3tAuKYUaOtZMbeeq1rKhJfUAr5HNLFgN7JS0uurCnAtRZA8dbaa2\nc1Ur0tBdP1PbuRnRnhRKGpLUkNRoNpuxYp1rS5GGLjRT28yGzWzQzAZjnAF0LkSRhu7KmdrO/Z+W\np77N7Lqkp4DPyN6DbJ+ZHau8MucCFHoth5kdBA5WXItzpfmZQpcUb2iXFG9olxRvaJeUSmas9Eg2\nP3pqemIerZ+w3+OFTS+Nk3M1TszgJmgcKTZjxffQLine0C4p3tAuKd7QLine0C4pRWasRPuAS+eq\nVmQP/RbhH3zjXEe1bGiL+AGXzlXNx9AuKdHeCix/W9QhaP1eZc5VJVpDm9kwMAzZqe9Yuc61w4cc\nLilFDtuNAF8DqyRNStpVfVnOhSkyp3BnJwpxLgYfcrikeEO7pHhDu6R4Q7ukVDIFS1ITONNis37g\nYoSri5XTrVleE6wws0Iz1ipp6EJXLDXMbLBbcro1y2tqjw85XFK8oV1S5rKhh7ssp1uzvKY2zNkY\n2rkq+JDDJcUb2iXFG9olxRvaJcUb2iXlHwqwCNjAEEHDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134379898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %getValue the price of tesla -> ['%getPrice']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %getPrice the price of tesla -> ['%asset']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %asset tesla -> ['$stock']\n",
      "WARNING: No attention outputs\n",
      "plz call me when the price of tesla is above 5 0\n",
      "( parsed (0, 12)\n",
      "    ( %if (0, 11)\n",
      "        ( %alert (0, 2)\n",
      "            ( %message_type (1, 1)\n",
      "                ( @call (1, 1) ) ) )\n",
      "        ( %condition (4, 11)\n",
      "            ( %getValue (4, 7)\n",
      "                ( %getPrice (4, 7)\n",
      "                    ( %asset (7, 7)\n",
      "                        ( $stock (7, 7) tesla ) ) ) )\n",
      "            ( $number (9, 11) above 5 0 ) ) ) )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nalgene.node.Node at 0x13c8c32b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_and_print('%', \"plz call me when the price of tesla is above 5 0\".split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) % hey maia if the ethereum price is less than 2 0 then turn the living room light on -> ['%if']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %if if the ethereum price is less than 2 0 then turn the living room light on -> ['%condition', '%sequence']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 5.2703e-02  9.8708e-01  9.9661e-01  9.3996e-01  9.6085e-01  9.9436e-01\n",
      " 1.7502e-04  6.1326e-02  4.3590e-04  4.6715e-04  2.5827e-04  6.9270e-04\n",
      "\n",
      "Columns 6 to 11 \n",
      " 8.5065e-01  9.8593e-01  9.4292e-01  5.1305e-03  1.3066e-03  8.0447e-03\n",
      " 2.4266e-03  1.3568e-02  2.9568e-02  2.8469e-01  9.8339e-01  9.9992e-01\n",
      "\n",
      "Columns 12 to 15 \n",
      " 1.4485e-02  1.6154e-03  1.0330e-03  8.6225e-06\n",
      " 9.9836e-01  9.9762e-01  9.9991e-01  9.9941e-01\n",
      "[torch.FloatTensor of size 2x16]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAABICAYAAACUY2yHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13386b4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %condition the ethereum price is less than 2 0 -> ['%getValue', '%operator', '$number']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 9.9964e-01  9.9971e-01  9.9871e-01  2.6355e-01  6.1660e-02  3.3172e-04\n",
      " 4.6563e-04  1.4216e-03  6.4425e-03  2.2843e-02  9.9206e-01  9.7696e-01\n",
      " 1.9768e-06  6.3569e-05  1.1907e-07  1.0644e-05  1.5179e-02  5.6186e-02\n",
      "\n",
      "Columns 6 to 7 \n",
      " 1.3233e-04  4.0747e-05\n",
      " 2.3411e-01  2.4424e-01\n",
      " 9.6682e-01  9.9454e-01\n",
      "[torch.FloatTensor of size 3x8]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAABaCAYAAAARg3zAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1340db550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %getValue the ethereum price -> ['%getPrice']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %getPrice the ethereum price -> ['%asset']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %asset ethereum -> ['@eth']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %operator less than -> ['@less_than']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %sequence turn the living room light on -> ['%action']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %action turn the living room light on -> ['%setLightState']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %setLightState turn the living room light on -> ['%light_name', '%light_state']\n",
      "Variable containing:\n",
      " 0.1356  0.9793  0.9996  0.9991  0.9432  0.0341\n",
      " 0.0001  0.0113  0.0103  0.0076  0.0320  0.9834\n",
      "[torch.FloatTensor of size 2x6]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAABICAYAAAAgTM2hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABHlJREFUeJzt3d2LFXUcx/H3p3XFSEFqDyEqahCBBZUtUhhSXVlJ3eZF\nV4E3BUUX0W3/gTfdLCIRPRFUECZFgVDRg66pqT1hspEi7PYgPRCF9u3iTLRFOON3fufs7OHzgsVz\n9OzHr+5nZ347OzOriMDsUl220APY4uTiWIqLYykujqW4OJbi4ljK0IsjaZukLyWdlPRki5w9kmYl\nHS8w01pJ+yV9JumEpEeTOcskHZB0tMp5qsBsY5IOS9rbImNG0jFJRyRNt50JgIgY2hswBnwNXAMs\nBY4CG5NZW4FNwPECc60CNlWPVwBfZeYCBCyvHo8DHwO3tpztceAFYG+LjBlgouTHcthbnM3AyYg4\nFRF/AC8B92eCIuJd4IcSQ0XE2Yj4pHr8M/A5sDqRExHxS/V0vHpLH2GVtAa4F9idzRiUYRdnNfDt\nvOenSXyABknSeuBm+luLzPuPSToCzAJvR0Qqp7ILeAL4s0UG9Mv7jqRDkna2zAK8OP4XScuBV4DH\nIuKnTEZEXIiIm4A1wGZJNyRn2Q7MRsShzPv/x+3VTHcDD0va2jZw2MU5A6yd93xN9XsLTtI4/dI8\nHxGvts2LiHPAfmBbMmILcJ+kGfq79LskPZec5Uz16yzwGv0lQzslF0wNFmlLgFPABv5ZHF/fIm89\nZRbHAp4FdrXM6QErq8eXA+8B2wvMdwfJxTFwBbBi3uMPgG1tZxrqFicizgOPAG/RX4C+HBEnMlmS\nXgQ+BK6TdFrSQy1G2wI8SP+z+kj1dk8iZxWwX9KnwEH6a5z0l9GFXA28L+kocAB4IyLebBuqqolm\nl8SLY0txcSzFxbEUF8dSXBxLWbDilDr0XSqnq1ldnAkWdotT6h9R7D+jo1ldnMm7KssZyAHAZVKs\nqHnNb/SPyddZd8uNF/3zubnv6fWuapC0pPYVc3Nz9Hq9Bln1mmf9WpNzjl5vZW3KsUNf1L7mAv0T\noi7mPHAhQnVZAylOT4rUSTb/Y3fMFUqaKJRT2kdFUtbrtiI5Z4HfGxTHuypLcXEsxcWxlEbFKXVl\ngo2O2uJIGgOepn/a4UZgh6SNgx7Muq3JFqfYlQk2OpoUp/NXJtjw1R8Va6j6PshO6J/YaqOtyRan\n0ZUJETEVEZMRMdnkiLAtbk2KcxC4VtIGSUuBB4DXBzuWdV3trioizkv6+8qEMWBP9soEGx2N1jgR\nsQ/YN+BZbBHxkWNLcXEsxcWxFBfHUgZyIteYFMsKZY0Xyimp7c1q5ruyUM5M/FgkZ3LyTqanD/tE\nLhsMF8dSXBxLcXEsxcWxlCZnABa7EbWNjiZbnGfI3wDRRlRtcaLgjahtdHiNYykDOXW09rCjLXrF\nihMRU8AU9L/lUCrXusm7Kktp8uV4yRtR24hocs7xjmEMYouLd1WW4uJYiotjKS6OpQzk1FFJc8A3\nNS+bAL4r8NeVyulq1rBnWhcRtXe9XLAfOyRpOiImu5LT1awuzgTeVVmSi2MpC1mcqY7ldDWrizP5\nRytajndVluLiWIqLYykujqW4OJbyF3/8EI+n8Q4pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134df8438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %light_name the living room light -> ['@living_room_light']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %light_state on -> ['@on']\n",
      "WARNING: No attention outputs\n",
      "hey maia if the ethereum price is less than 2 0 then turn the living room light on\n",
      "( parsed (0, 18)\n",
      "    ( %if (2, 17)\n",
      "        ( %condition (3, 10)\n",
      "            ( %getValue (3, 5)\n",
      "                ( %getPrice (3, 5)\n",
      "                    ( %asset (4, 4)\n",
      "                        ( @eth (4, 4) ) ) ) )\n",
      "            ( %operator (7, 8)\n",
      "                ( @less_than (7, 8) ) )\n",
      "            ( $number (9, 10) 2 0 ) )\n",
      "        ( %sequence (12, 17)\n",
      "            ( %action (12, 17)\n",
      "                ( %setLightState (12, 17)\n",
      "                    ( %light_name (13, 16)\n",
      "                        ( @living_room_light (13, 16) ) )\n",
      "                    ( %light_state (17, 17)\n",
      "                        ( @on (17, 17) ) ) ) ) ) ) )\n",
      "\n",
      "(evaluate) % hey maia what's the ethereum price -> ['%sequence']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %sequence maia what's the ethereum price -> ['%action']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %action maia what's the ethereum price -> ['%getPrice']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %getPrice maia what's the ethereum price -> ['%asset']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %asset ethereum -> ['@eth']\n",
      "WARNING: No attention outputs\n",
      "hey maia what's the ethereum price\n",
      "( parsed (0, 6)\n",
      "    ( %sequence (1, 5)\n",
      "        ( %action (1, 5)\n",
      "            ( %getPrice (1, 5)\n",
      "                ( %asset (4, 4)\n",
      "                    ( @eth (4, 4) ) ) ) ) ) )\n",
      "\n",
      "(evaluate) % hey maia play some Skrillex please and then turn the office light off -> ['%sequence']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %sequence play some Skrillex please and then turn the office light off -> ['%action', '%action']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.9526  0.9978  0.9990  0.0041  0.0562  0.0002  0.1132  0.3451  0.4552  0.0309\n",
      " 0.0011  0.0010  0.0004  0.0000  0.0002  0.0003  0.6951  0.9750  0.8843  0.9196\n",
      "\n",
      "Columns 10 to 10 \n",
      " 0.0057\n",
      " 0.9734\n",
      "[torch.FloatTensor of size 2x11]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAABICAYAAAAXggKVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134e5feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %action play some Skrillex -> ['%playMusic']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %playMusic play some Skrillex -> ['$artist_name']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %action turn the office light off -> ['%setLightState']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %setLightState turn the office light off -> ['%light_name', '%light_state']\n",
      "Variable containing:\n",
      " 0.1775  0.9770  0.9984  0.9725  0.1154\n",
      " 0.0001  0.0119  0.0117  0.0799  0.9750\n",
      "[torch.FloatTensor of size 2x5]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHwAAABICAYAAAA09ZEFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABBBJREFUeJztnc+LHEUcxT/PzcYYIgTNHDbZxUQQYVXUuAQhIOIpatCj\n5uBJWC+C4iF4E/+DXLwsEkT8RUAPEgLiYUUPotnVRBNFiYtiJLATo6gEDNHnYVpcFdNlT033aH0/\n0NA9W/Pm7byt6pru79TKNkE5XNa1gaBdIvDCiMALIwIvjAi8MCLwwmg9cEl7JH0m6ZSkJ4fQOShp\nVdKJDJ5mJC1K+kTSSUmPNdTZIOl9SccrnaczeJuQ9KGkw8NqAWC7tQ2YAL4ArgXWA8eB2YZadwA7\ngRMZfE0BO6v9K4HPm/gCBGyq9ieB94Dbh/T2BPAScDhHBm338F3AKdsrti8ArwD3NxGy/TZwLocp\n22dsf1Dt/wh8CmxroGPbP1WHk9XW+MqWpGngXuDZphp/pe3AtwFfrzk+TYM3dpRI2g7cyqB3Nnn+\nhKRjwCrwpu1GOhUHgP3Ar0No/ImYtK1B0ibgVeBx2z800bD9i+1bgGlgl6QbG3rZC6zaXm7y/H+i\n7cC/AWbWHE9Xj3WOpEkGYb9o+7Vh9Wx/DywCexpK7Abuk/Qlg1PfXZJeGNZX25O2dcAKsIM/Jm03\nDKG3nTyTNgHPAweG1OkBm6v9K4B3gL0Z/N3Jf3HSZvsi8CjwBoOJ0SHbJ5toSXoZeBe4XtJpSQ8P\nYW038BCDXnSs2u5poDMFLEr6CDjK4Bye5+NUJlT9BQWFEJO2wojACyMCL4wIvDAi8MLoLHBJ8+Ok\nM65aOT1Btz081y+S8w0ZR63/TeBBB4zkwstGyZtr2pwHNiZobb3t5kv+vN//ll7v6gSldbUt+v0+\nvV4vQetCgtY5er2rLtlmZfnjWp2fgcsTHH0HZ23Xmh9J4FslP5JJ6yn3MyltyaQDg7u6w/OAZuob\nJXIIlm3P1bWLIb0wIvDCiMALIwIvjKTAc5UWB91TG7ikCeAZ4G5gFtgnaXbUxoLRkNLDs5UWB92T\nEnhSabGkeUlLkpbO53IXZCfbpM32gu0523MpV9CCbkgJfGxLi4N/T0rgR4HrJO2QtB54EHh9tLaC\nUVF7R8H2RUm/lxZPAAeblhYH3VN/CwmwfQQ4MmIvQQvElbbCiMALIwIvjJEUQExI3pBJK5dOTm7K\npPOWz2RSAmkqCiCCvxOBF0YEXhgReGFE4IWRUgCRbQG8oHtSevhzNF+YJhgzagN3xgXwgu6Jc3hh\nJN0tS6H6Wus8DNbACsaTbIHbXgAWYHBpNZdukJcY0gsj5WNZzgXwgo5JKXHa14aRoB1iSC+MCLww\nIvDCiMALYyQlTpL6wFc1zbYAZzO8XC6dcdVK1bmms0V9UpC0lFKD1ZbOuGrl9AQxpBdHBF4YXQa+\nMGY646qV01P8C4zSiCG9MCLwwojACyMCL4wIvDB+AwzmmC2gRoyrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1343e5d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %light_name the office light -> ['@office_light']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %light_state off -> ['@off']\n",
      "WARNING: No attention outputs\n",
      "hey maia play some Skrillex please and then turn the office light off\n",
      "( parsed (0, 13)\n",
      "    ( %sequence (2, 12)\n",
      "        ( %action (2, 4)\n",
      "            ( %playMusic (2, 4)\n",
      "                ( $artist_name (4, 4) Skrillex ) ) )\n",
      "        ( %action (8, 12)\n",
      "            ( %setLightState (8, 12)\n",
      "                ( %light_name (9, 11)\n",
      "                    ( @office_light (9, 11) ) )\n",
      "                ( %light_state (12, 12)\n",
      "                    ( @off (12, 12) ) ) ) ) ) )\n",
      "\n",
      "(evaluate) % turn the office light up and also could you please turn off the living room light and make the temperature of the bedroom to 6 thank you maia -> ['%sequence']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %sequence turn the office light up and also could you please turn off the living room light and make the temperature of the bedroom to 6 -> ['%action', '%action', '%action']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 9.9543e-01  9.9931e-01  9.9962e-01  9.9835e-01  9.7091e-01  3.5177e-03\n",
      " 2.2957e-02  9.8036e-03  1.4652e-03  3.3185e-03  1.4501e-02  5.7223e-04\n",
      " 4.4044e-05  1.4737e-06  3.2747e-08  7.4998e-08  2.9953e-07  1.9099e-08\n",
      "\n",
      "Columns 6 to 11 \n",
      " 1.4380e-05  5.3929e-06  1.0750e-06  2.8122e-08  8.0415e-05  3.6781e-04\n",
      " 1.1129e-03  6.2825e-03  2.5884e-03  1.1548e-03  9.0924e-01  9.0973e-01\n",
      " 7.7146e-08  1.3063e-06  1.6668e-06  4.9748e-06  3.0601e-02  5.1231e-02\n",
      "\n",
      "Columns 12 to 17 \n",
      " 7.7496e-05  9.1006e-05  9.5520e-05  8.5558e-06  2.7558e-10  3.4114e-09\n",
      " 9.6433e-01  9.5907e-01  8.9054e-01  5.7409e-01  2.7781e-04  4.7989e-02\n",
      " 1.8130e-01  1.4259e-01  2.5116e-01  2.4696e-01  1.7988e-03  7.2405e-01\n",
      "\n",
      "Columns 18 to 23 \n",
      " 3.2813e-09  2.5748e-09  1.5908e-09  2.3186e-09  3.5733e-08  3.5241e-09\n",
      " 5.9691e-02  6.8430e-02  8.6925e-03  6.0320e-03  2.6470e-02  2.8023e-03\n",
      " 8.2102e-01  8.0763e-01  8.2717e-01  8.7059e-01  9.2982e-01  8.0895e-01\n",
      "\n",
      "Columns 24 to 24 \n",
      " 1.4095e-09\n",
      " 6.5334e-03\n",
      " 9.2120e-01\n",
      "[torch.FloatTensor of size 3x25]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAABaCAYAAABHXATaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133874cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %action turn the office light up -> ['%setLightState']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %setLightState turn the office light up -> ['%light_name', '%light_state']\n",
      "Variable containing:\n",
      " 0.1112  0.9599  0.9965  0.9061  0.0086\n",
      " 0.0001  0.0106  0.0106  0.0683  0.9011\n",
      "[torch.FloatTensor of size 2x5]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHwAAABICAYAAAA09ZEFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABA5JREFUeJztnc+LVWUch59P11EjhSm6C3EkFaIaW5QNEggRtbGS2uYi\nCIpZBUWLaNt/4KbNEFLRL4pahAjRYqAWUc7UGJoUJkZGMGOl2cZQPy3uiaYg7+u57z3n1Pt94MA5\nM+/9zPfeZ95z3nt473tlm6Acrmm7gKBZQnhhhPDCCOGFEcILI4QXRuPCJe2R9LWkE5KeHyHngKRl\nSUcz1LRF0rykryQdk/R0zZz1kj6TdKTKeSFDbT1JX0g6OGoWALYb24Ae8C2wHVgLHAGma2bdA+wE\njmaoaxOws9rfCHxTpy5AwIZqfwL4FLh7xNqeBd4ADuZw0HQP3wWcsH3S9u/AW8AjdYJsfwT8nKMo\n2z/a/rzaPw8cBzbXyLHt36rDiWqrfWdL0hTwEPBS3Yx/0rTwzcD3q45PU+OFHSeStgJ3MuiddR7f\nk7QELAMf2q6VU7EfeA64PELG34hB2yokbQDeBZ6x/WudDNuXbN8BTAG7JN1es5a9wLLtxTqP/zea\nFv4DsGXV8VT1s9aRNMFA9uu23xs1z/ZZYB7YUzNiN/CwpFMMLn33SXpt1LqaHrStAU4C2/hr0LZj\nhLyt5Bm0CXgV2D9iTh+YrPavBT4G9mao717+i4M22xeBp4APGAyM3rZ9rE6WpDeBT4BbJJ2W9MQI\npe0GHmPQi5aq7cEaOZuAeUlfAocZXMPzvJ3KhKr/oKAQYtBWGCG8MEJ4YYTwwgjhhdGacEmzXcrp\nalbOmqDdHp7rieR8QbqY9b8RHrTAWG68rJN83ZA2F4B1CVnb79pxxd+vrPxCv399QtL6oS1WVlbo\n9/sJWT8lZJ2n3994xTZLi6eG5lwmrVdegjO2hxY/FuE3SL4/U9Y7Pp4p6dZMOQCvZEmZ1ONZcgDO\nwaLtmWHt4pReGCG8MEJ4YYTwwkgSnmtqcdA+Q4VL6gEvAg8A08A+SdPjLiwYDyk9PNvU4qB9UoQn\nTS2WNCtpQdLChVzVBdnJNmizPWd7xvZMyh20oB1ShHd2anFw9aQIPwzcLGmbpLXAo8D74y0rGBdr\nhjWwfVHSn1OLe8CBulOLg/YZKhzA9iHg0JhrCRog7rQVRggvjBBeGEnX8KvlHPku+JO6LVNSPnJN\npTjrbJ/zR3oyqV308MII4YURwgsjhBdGCC+MlAkQ2RbAC9onpYe/TP2FaYKOMVS4My6AF7RPXMML\nI9udtupjrbMwWAMr6CbZhNueA+YAelIsDdVR4pReGClvy3IugBe0TMoUp31NFBI0Q5zSCyOEF0YI\nL4wQXhhjWeNF0grw3ZBmNwJnMvy5XDldzUrNuam1RX1SkLSQsghNUzldzcpZE8QpvThCeGG0KXyu\nYzldzcpZU3wFRmnEKb0wQnhhhPDCCOGFEcIL4w/UEpItIy76EQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134e6edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %light_name the office light -> ['@office_light']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %light_state up -> ['@up']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %action turn off the living room light -> ['%setLightState']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %setLightState turn off the living room light -> ['%light_name', '%light_state']\n",
      "Variable containing:\n",
      " 0.2023  0.8455  0.1936  0.8200  0.6191  0.0178\n",
      " 0.0001  0.0816  0.0250  0.0229  0.0279  0.2038\n",
      "[torch.FloatTensor of size 2x6]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAABICAYAAAAgTM2hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABIZJREFUeJzt3U+IVXUYxvHv0zhiNEaFVxG1NIjAWpSaBIZEKy2pXeSi\nVeSmwKiotm2jhZs2U0hE/ygqCLOiQKgo8k85pUVlMpUSzUSGuQhT3xb3RtbCc3zP7945c3k+cPFe\nvfP46jxzzm/OPeeOIgKz83XBTA9gs5OLYykujqW4OJbi4liKi2MpAy+OpA2SvpF0SNJjDXK2S5qS\ndKDATMsk7ZL0laSDkrYmc+ZJ2i1popfzeIHZRiR9LmlHg4xJSV9K2i9pb9OZAIiIgd2AEeB74Epg\nLjABrExmrQdWAQcKzLUYWNW7Px/4NjMXIGCsd38U+BS4seFsDwIvAjsaZEwCC0p+Lge9xVkLHIqI\nwxFxEngZuCMTFBEfAL+VGCoifo6Iz3r3/wC+BpYkciIiTvQejvZu6SOskpYCtwHPZDP6ZdDFWQL8\ndNbjIyQ+Qf0kaTlwPd2tRebjRyTtB6aA9yIildOzDXgEONMgA7rlfV/SPklbGmYBXhz/h6Qx4DXg\ngYg4nsmIiNMRcR2wFFgr6drkLJuAqYjYl/n4/7mpN9NG4D5J65sGDro4R4FlZz1e2vu9GSdplG5p\nXoiI15vmRcTvwC5gQzJiHXC7pEm6u/RbJD2fnOVo79cp4A26S4ZmSi6YaizS5gCHgRX8uzi+pkHe\ncsosjgU8B2xrmNMBLundvxD4ENhUYL6bSS6OgYuA+Wfd/xjY0HSmgW5xIuIUcD/wLt0F6CsRcTCT\nJekl4BPgaklHJN3TYLR1wN10v6r39263JnIWA7skfQHsobvGSX8bXcgi4CNJE8Bu4K2IeKdpqHpN\nNDsvXhxbiotjKS6Opbg4luLiWMqMFafUoe9SOW3NauNMMLNbnFL/iGL/GS3NauNM3lVZTl8OAI5J\ncVnFc04AYzWyFq5ecM4/n57+k05nXmXOL/t+rXxO3ZkWrb648jnT0yfpdOZWhx0792up08ehU/3X\nMXG4+jlnqN5SnAbORKgqqy/FuVyKhwplbY17i+Q8qaeL5AA8HBuLZfHq20ViFt5ZJIZjwF81iuNd\nlaW4OJbi4lhKreKUujLBhkdlcSSNAE/RPe1wJbBZ0sp+D2btVmeLU+zKBBsedYrT+isTbPDmlArq\nvQ6yBeDSUqHWWnW2OLWuTIiI8YhYExFr6hx9tdmtTnH2AFdJWiFpLnAX8GZ/x7K2q9xVRcQpSf9c\nmTACbM9emWDDo9YaJyJ2Ajv7PIvNIj5ybCkujqW4OJbi4lhKX07kGpGi+py8em4olPNdoRzoniVX\nymihnEcL5TwB/OgTuaxfXBxLcXEsxcWxFBfHUuqcAVjsjahteNTZ4jxL/g0QbUhVFicKvhG1DQ+v\ncSylL6eOVh52tFmvWHEiYhwYh+5LDqVyrZ28q7KUOt+Ol3wjahsSdc453jyIQWx28a7KUlwcS3Fx\nLMXFsZS+nDoqaRr4oeJpC4Dqd3SsViqnrVmDnumKiOhUBc3Yjx2StDci1rQlp61ZbZwJvKuyJBfH\nUmayOOMty2lrVhtn8o9WtBzvqizFxbEUF8dSXBxLcXEs5W8iKRKYO+/m6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134d54b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %light_name off living room -> ['@living_room_light']\n",
      "WARNING: No attention outputs\n",
      "WARNING: Empty inputs\n",
      "\n",
      "(evaluate) %action make the temperature of the bedroom to 6 -> ['%setTemperature']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %setTemperature make the temperature of the bedroom to 6 -> ['%room_name', '$temperature']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 1.5998e-03  1.1430e-02  1.4474e-03  4.3956e-03  6.1450e-02  9.8775e-01\n",
      " 7.2643e-07  5.2093e-06  4.0760e-06  6.0852e-06  7.2367e-05  6.5544e-04\n",
      "\n",
      "Columns 6 to 7 \n",
      " 2.9442e-03  6.1333e-02\n",
      " 2.0923e-02  9.8676e-01\n",
      "[torch.FloatTensor of size 2x8]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAABICAYAAABfnd9QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABThJREFUeJzt3d+LVHUcxvH307ZWrKKBexGuqFEsLBFqIkUikRRqYbcK\n3RneFCRdRBEE/QPRTQRiVlAZZD8IEaJI6CYqdbX8GRqKK9quRWh14a9PF+csLBXN2XO+Z3b48rxg\ncHZ39tnPzD5z9jtz5jiKCMxycdNMD2CWkgttWXGhLSsutGXFhbasuNCWla4XWtJaSScknZT0QoOc\nHZLGJR1OMNNCSXslHZV0RNKzNXNulfSdpENlzisJZuuTNCppd4OM05J+lHRQ0r6G88yTtEvScUnH\nJD1QM2e4nGfydEnS1iazARARXTsBfcAp4E5gFnAIGKmZtRpYDhxOMNcdwPLy/BzgpzpzAQJml+f7\ngW+B+xvO9hzwPrC7QcZpYH6i3+E7wFPl+VnAvES9uAAsaprV7S30SuBkRPwcEVeAD4An6gRFxNfA\nbymGiojzEXGgPH8ZOAYsqJETEfFH+WF/eaq950rSEPAYsL1uRkqS5lJsSN4EiIgrEfF7gug1wKmI\nONM0qNuFXgCcnfLxGDWK0yZJi4FlFFvXOt/fJ+kgMA58ERG1ckqvAc8DNxpkQHGn+lLSfklbGuQs\nASaAt8pl0HZJAw1nA9gI7EyQ4weFU0maDXwEbI2IS3UyIuJ6RCwFhoCVku6pOcvjwHhE7K/z/f+w\nqpxpHfC0pNU1c26mWOa9ERHLgD+B2o+DACTNAjYAHzbJmdTtQp8DFk75eKj83IyT1E9R5vci4uOm\neeWf4r3A2poRDwIbJJ2mWJo9LOndmrOcK/8dBz6hWPrVMQaMTfmrs4ui4E2sAw5ExC8Nc4DuF/p7\n4G5JS8p75kbgsy7P8C+SRLEuPBYRrzbIGZQ0rzx/G/AIcLxOVkS8GBFDEbGY4nb6KiKerDHTgKQ5\nk+eBR4FazwxFxAXgrKTh8lNrgKN1sqbYRKLlBtDdZznKR7TrKZ5FOAW81CBnJ3AeuEqx5djcIGsV\nxTrzB+BgeVpfI+deYLTMOQy8nOg2e4iaz3JQPKN0qDwdaXKbl3lLgX3ldfwUuL1B1gDwKzA3Vb9U\nBptlwQ8KLSsutGXFhbasuNCWFRfasjJjhW64CzZ5Tq9meabpmcktdKorkvIG6cUszzQNXnJYVlrZ\nsSIpOt1TguLFwx2zOnz9BtXulVWuZdWZqqiSdUuFnGsUrwjqZOS+ZR0vMzFxkcHB+R0vN7p/9H+/\nXvV2SnX9rgDXIir9alopdJ8UtybK6k+UczVRDhSvRk/hrkQ5AAficrKsgeKlH40Nd75IJceBvyoW\n2ksOy4oLbVlxoS0rlQqd6khts7Z1LLSkPuB1iiMLRoBNkkbaHsysjipb6GRHapu1rUqhe/5IbbNJ\nVZ6zr6TcJ78F0u2cMJuuKoWudKR2RGwDtkGxYyXJdGbTVGXJ0ZNHapv9l45b6Ii4JukZ4HOKvb47\nIuJI65OZ1VBpDR0Re4A9Lc9i1pj3FFpWXGjLigttWXGhLSvJdqy0JeUL81O5nijnRKIcSPeifCje\nwiCFVAcdrFhR/X//9RbasuJCW1ZcaMuKC21ZcaEtK1WOWEn2BpdmbauyhX6b+m98Y9ZVHQsdCd/g\n0qxtXkNbVnwIlmUlWaF9CJb1Ai85LCtVnrbbCXwDDEsak7S5/bHM6qlyTOGmbgxiloKXHJYVF9qy\n4kJbVlxoy0pbbxo0AZzpcLH5wMUEPy5VTq9meSZYFBGDVcJaKXSlHyzti4gVvZLTq1meaXq85LCs\nuNCWlZks9LYey+nVLM80DTO2hjZrg5cclhUX2rLiQltWXGjLigttWfkb27r1ZsD+b3kAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1430f6f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %room_name bedroom -> ['@bathroom']\n",
      "WARNING: No attention outputs\n",
      "turn the office light up and also could you please turn off the living room light and make the temperature of the bedroom to 6 thank you maia\n",
      "( parsed (0, 28)\n",
      "    ( %sequence (0, 24)\n",
      "        ( %action (0, 4)\n",
      "            ( %setLightState (0, 4)\n",
      "                ( %light_name (1, 3)\n",
      "                    ( @office_light (1, 3) ) )\n",
      "                ( %light_state (4, 4)\n",
      "                    ( @up (4, 4) ) ) ) )\n",
      "        ( %action (10, 15)\n",
      "            ( %setLightState (10, 15)\n",
      "                ( %light_name (11, 11)\n",
      "                    ( @living_room_light (11, 13) ) )\n",
      "                ( %light_state [] ) ) )\n",
      "        ( %action (17, 24)\n",
      "            ( %setTemperature (17, 24)\n",
      "                ( %room_name (22, 22)\n",
      "                    ( @bathroom (22, 22) ) )\n",
      "                ( $temperature (24, 24) 6 ) ) ) ) )\n",
      "\n",
      "(evaluate) % turn the living room light off and turn the bedroom light up and also turn the volume up -> ['%setLightState']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %setLightState turn the living room light off and turn the bedroom light up and also turn the volume up -> ['%light_name', '%light_state']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 8.2453e-01  9.9735e-01  9.9983e-01  9.9985e-01  9.9704e-01  9.6383e-01\n",
      " 1.6499e-04  4.7618e-03  2.8669e-03  2.5954e-03  2.0595e-03  1.7571e-01\n",
      "\n",
      "Columns 6 to 11 \n",
      " 5.3868e-02  1.2612e-03  2.6578e-02  2.1230e-02  1.8833e-02  1.2795e-03\n",
      " 6.4355e-03  1.3239e-03  1.3316e-02  4.4142e-04  4.8845e-03  6.8358e-02\n",
      "\n",
      "Columns 12 to 17 \n",
      " 1.8915e-04  3.1719e-06  1.0156e-06  1.7680e-06  6.0462e-07  2.7580e-08\n",
      " 9.0607e-03  2.1724e-04  5.7884e-04  4.6274e-03  5.8008e-03  8.3872e-02\n",
      "[torch.FloatTensor of size 2x18]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABICAYAAADWIB8QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1430e2518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %light_name turn the living room light off -> ['@living_room_light']\n",
      "WARNING: No attention outputs\n",
      "WARNING: Empty inputs\n",
      "turn the living room light off and turn the bedroom light up and also turn the volume up\n",
      "( parsed (0, 18)\n",
      "    ( %setLightState (0, 17)\n",
      "        ( %light_name (0, 5)\n",
      "            ( @living_room_light (0, 5) ) )\n",
      "        ( %light_state [] ) ) )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nalgene.node.Node at 0x1430e29b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_and_print('%', \"hey maia if the ethereum price is less than 2 0 then turn the living room light on\".split(' '))\n",
    "evaluate_and_print('%', \"hey maia what's the ethereum price\".split(' '))\n",
    "evaluate_and_print('%', \"hey maia play some Skrillex please and then turn the office light off\".split(' '))\n",
    "evaluate_and_print('%', \"turn the office light up and also could you please turn off the living room light and make the temperature of the bedroom to 6 thank you maia\".split(' '))\n",
    "evaluate_and_print('%', \"turn the living room light off and turn the bedroom light up and also turn the volume up\".split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words ['heya', 'shoot', 'me', 'an', 'email', 'if', 'the', 'price', 'of', 'bitcoin', 'is', 'bigger', 'than', '3', '0', '0', '0', 'would', 'ya']\n",
      "\n",
      "(evaluate) % heya shoot me an email if the price of bitcoin is bigger than 3 0 0 0 would ya -> ['%if']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %if shoot me an email if the price of bitcoin is bigger than 3 0 0 0 -> ['%alert', '%condition']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.9998  0.9988  0.8995  0.9537  0.0081  0.2099  0.0483  0.0483  0.0197  0.0019\n",
      " 0.0008  0.0010  0.0001  0.0120  0.0746  0.9887  0.9968  0.9992  0.9989  0.9993\n",
      "\n",
      "Columns 10 to 15 \n",
      " 0.0091  0.0016  0.0103  0.0037  0.0014  0.0007\n",
      " 0.9991  0.9975  0.9996  0.9993  0.9990  0.9987\n",
      "[torch.FloatTensor of size 2x16]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAABICAYAAACUY2yHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134ec6668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %alert shoot me an email -> ['%message_type']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %message_type email -> ['@email']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %condition the price of bitcoin is bigger than 3 0 0 0 -> ['%getValue', '%operator', '$number']\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 9.9992e-01  9.9996e-01  9.9954e-01  9.9435e-01  1.0395e-01  1.7570e-02\n",
      " 2.0009e-04  2.4964e-03  1.0730e-02  8.7231e-03  2.3112e-02  9.8321e-01\n",
      " 3.6184e-07  2.1461e-08  1.5177e-06  7.3842e-06  1.5524e-05  7.0941e-04\n",
      "\n",
      "Columns 6 to 10 \n",
      " 8.0400e-04  3.7924e-04  1.7648e-04  5.0516e-05  1.0655e-05\n",
      " 9.8296e-01  1.7921e-01  1.6781e-01  1.9078e-01  1.9987e-01\n",
      " 3.0326e-02  9.3317e-01  9.9116e-01  9.9779e-01  9.9905e-01\n",
      "[torch.FloatTensor of size 3x11]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAABaCAYAAABZnKEFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyTDDNOGzmaEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133872b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(evaluate) %getValue the price of bitcoin -> ['%getPrice']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %getPrice the price of bitcoin -> ['%asset']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %asset bitcoin -> ['@btc']\n",
      "WARNING: No attention outputs\n",
      "\n",
      "(evaluate) %operator bigger than -> ['@greater_than']\n",
      "WARNING: No attention outputs\n",
      "heya shoot me an email if the price of bitcoin is bigger than 3 0 0 0 would ya\n",
      "( parsed (0, 19)\n",
      "    ( %if (1, 16)\n",
      "        ( %alert (1, 4)\n",
      "            ( %message_type (4, 4)\n",
      "                ( @email (4, 4) ) ) )\n",
      "        ( %condition (6, 16)\n",
      "            ( %getValue (6, 9)\n",
      "                ( %getPrice (6, 9)\n",
      "                    ( %asset (9, 9)\n",
      "                        ( @btc (9, 9) ) ) ) )\n",
      "            ( %operator (11, 12)\n",
      "                ( @greater_than (11, 12) ) )\n",
      "            ( $number (13, 16) 3 0 0 0 ) ) ) )\n",
      "response {'parsed': {'key': 'parsed', 'position': (0, 19), 'children': [{'key': '%if', 'position': (1, 16), 'children': [{'key': '%alert', 'position': (1, 4), 'children': [{'key': '%message_type', 'position': (4, 4), 'children': [{'key': '@email', 'position': (4, 4), 'children': []}]}]}, {'key': '%condition', 'position': (6, 16), 'children': [{'key': '%getValue', 'position': (6, 9), 'children': [{'key': '%getPrice', 'position': (6, 9), 'children': [{'key': '%asset', 'position': (9, 9), 'children': [{'key': '@btc', 'position': (9, 9), 'children': []}]}]}]}, {'key': '%operator', 'position': (11, 12), 'children': [{'key': '@greater_than', 'position': (11, 12), 'children': []}]}, {'key': '$number', 'position': (13, 16), 'children': ['3 0 0 0']}]}]}]}, 'words': ['heya', 'shoot', 'me', 'an', 'email', 'if', 'the', 'price', 'of', 'bitcoin', 'is', 'bigger', 'than', '3', '0', '0', '0', 'would', 'ya']}\n"
     ]
    }
   ],
   "source": [
    "def parse(s, cb):\n",
    "    words = tokenize_sentence(s)\n",
    "    print('words', words)\n",
    "    try:\n",
    "        evaluated = evaluate_and_print('%', words)\n",
    "        cb({'words': words, 'parsed': evaluated.to_json()})\n",
    "    except Exception:\n",
    "        cb({'error': \"Failed to evaluate\"})\n",
    "\n",
    "parse('heya shoot me an email if the price of bitcoin is bigger than 3 0 0 0 would ya', lambda r: print(\"response\", r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZMQError",
     "evalue": "Address already in use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZMQError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d649229162be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msomata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msomata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maia:parser'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'parse'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'bind_port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8855\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/sean/python_modules/somata/service.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, methods, options)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Create the binding socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROUTER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tcp://0.0.0.0:%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bind_port'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Deregister when killed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.bind (zmq/backend/cython/socket.c:5653)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/sean/anaconda3/lib/python3.5/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:10014)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mZMQError\u001b[0m: Address already in use"
     ]
    }
   ],
   "source": [
    "import somata\n",
    "service = somata.Service('maia:parser', {'parse': parse}, {'bind_port': 8855})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "service.socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
