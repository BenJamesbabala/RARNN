{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Change the volume high.\n",
      "( %\n",
      "    ( %setVolume (0, 3, 4)\n",
      "        ( $up_down (3, 3, 1) high ) ) )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nalgene.generate import *\n",
    "\n",
    "parsed, _, _ = generate_from_file('.', 'grammar.nlg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descend(node, fn, child_type='phrase', returns=None):\n",
    "    if returns is None: returns = []\n",
    "    returned = fn(node)\n",
    "    returns.append(returned)\n",
    "\n",
    "    for child in node.children:\n",
    "        if (child_type is None) or (child.type == child_type):\n",
    "            descend(child, fn, child_type, returns)\n",
    "    \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ascend(node, fn):\n",
    "    if node.parent is None:\n",
    "        return fn(node)\n",
    "    else:\n",
    "        return ascend(node.parent, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building input and output vocabularies\n",
    "\n",
    "To find all input vocabulary tokens, we can traverse the parsed nalgene tree and copy all `word` type tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EOS', 'Heroes', 'Machine', 'Hayko', 'Skrillex', 'Own', 'Summer', 'Funky', 'Breeze', 'Yakup', 'Coldplay', 'Got', 'Day', 'Seaside', 'Such', 'volume', 'Remaster', '10', 'get', 'Of', 'Melody', 'Dogulu', 'Original', 'Louie', 'Eyes', 'maia', 'Train', 'shit', 'music', 'Had', '3', 'plox', '6', 'Pinhani', 'Reha', 'Introduction', 'turn', 'change', 'by', 'Sleeps', 'Darkness', 'please', 'Furtado', 'Agua', 'and', 'Jizz', 'Out', 'Army', 'state', 'Attack', 'Athena', 'Sexbomb', '12', 'Stripes', 'Black', '2', 'put', 'Firestarter', 'Sezen', 'than', 'low', 'Iris', 'Morrissey', 'Take', 'red', 'Massive', 'coffee', 'Daydream', 'Remixed', \"what's\", 'hot', '11', 'Any', 'Diken', 'Duman', 'yen', 'is', 'the', 'Naive', 'Space', 'kitchen', 'Back', 'Breathe', 'With', 'bathroom', 'Night', 'Her', 'Best', 'For', 'Hate', 'Edit', '16', 'Your', 'My', 'you', 'Sheriff', 'light', 'outside', 'Turning', 'Imbruglia', 'Go', 'Seven', 'Annique', 'When', 'Rappers', 'Boogie', 'pretty', 'what', 'um', 'Blame', 'Shades', 'then', 'Baby', 'tesla', 'Valerie', 'pls', 'Will', 'Placebo', 'Beirut', 'Cepkin', 'Under', '13', 'She', 'Ceza', 'Lion', 'from', 'to', 'purple', 'basement', 'Berlin', 'Sharona', 'I', 'Modern', 'Way', 'On', 'Nite', 'Devil', 'ethereum', 'room', 'Great', 'Someday', 'white', 'up', 'greater', 'are', 'something', 'yellow', 'temperature', 'Soul', 'Feel', 'Shout', 'Happy', 'Malice', 'green', 'Somebody', 'Moves', 'Where', 'Deniz', 'Let', 'Falay', 'price', 'Did', 'Time', 'in', 'Last', 'Dagger', 'Sex', 'Love', 'Really', 'Cure', 'Kenan', 'blue', 'To', 'set', 'People', 'Human', 'Together', 'You', 'Pants', 'Every', 'make', 'Delilah', 'So', 'Goes', '19', 'Japanese', 'Our', 'living', 'White', 'next', 'Say', 'also', 'Paint', 'btc', 'Have', 'Jay-Jay', 'Call', 'Natalie', 'Pass', 'very', 'Ufuk', 'Nelly', 'From', 'Nation', 'Tonight', 'Thumb', 'plx', 'Bon', 'Up', 'Shit', 'Muse', 'All', 'Boys', 'plate', 'tea', 'There', 'de', 'Ferah', 'Gang', 'tell', 'Fit', 'Jovi', 'Heights', 'some', 'Sweet', 'New', 'Dry', 'Dream', '5', 'Single', 'song', 'Nev', 'Delight', 'much', 'Aerosmith', 'Radio', 'Maroon', 'Know', 'A', 'Vega', 'Radiohead', 'Shelter', 'Brown', 'lhan', 'Heart', 'Chelsea', 'Were', 'Town', 'if', 'Apache', 'Elsiane', 'Blonde', 'me', 'Disposition', 'orange', '8', '14', 'hello', 'Do', 'Afternoon', 'Sesen', 'The', 'oh', 'equal', 'Girl', 'Age', '18', 'microsoft', 'Yansimasi', 'Oasis', 'Can', 'Believer', 'play', 'uh', 'Lola', 'bitcoin', 'Omen', 'Kurban', 'Told', 'Whitesnake', 'Bitch', 'a', 'Sunset', 'Full', 'Album', 'of', 'Is', 'Unchained', 'Smack', '4', 'Version', 'Wet', 'Jailbreak', 'Yildirim', 'thank', 'Badem', 'But', 'office', 'Called', '9', 'hi', 'Breath', 'Gimme', 'Dolapdere', 'Mono', 'Redhead', 'off', 'Isigin', 'Are', 'switch', 'on', 'It', 'Shot', 'pesos', 'Peaches', 'thx', 'thanks', 'Me', 'In', '17', 'Waterloo', 'Sebnem', 'Seki', 'less', 'Sympathy', 'eth', 'bedroom', 'Gathering', '1', '20', 'high', 'Cover', 'pot', 'Korn', 'Just', 'Johanson', 'Theme', 'Voodoo', '7', 'hey', 'Big', 'heya', 'Many', 'there', 'Sunny', 'Golden', 'could', 'And', 'how', 'yo', 'Be', 'Young', 'Aksu', '15', 'Shut', 'down']\n"
     ]
    }
   ],
   "source": [
    "input_tokens = []\n",
    "\n",
    "def print_tokens(node):\n",
    "    if node.type == 'word':\n",
    "        input_tokens.append(node.key)\n",
    "\n",
    "descend(parsed, print_tokens, None)\n",
    "\n",
    "input_tokens = list(set(input_tokens))\n",
    "input_tokens = ['EOS'] + input_tokens\n",
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For output tokens, we can just take the top level node names that are either phrases or variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EOS', '%', '%if', '%sequence', '%condition', '%checkValue', '%getNumberValue', '%getValue', '%action', '%checkLightState', '%checkSwitchState', '%getLightState', '%getSwitchState', '%getTemperature', '%getPrice', '%setLightState', '%light_state', '%setSwitchState', '%setTemperature', '%setVolume', '%playMusic', '$operator', '$asset', '$room', '$light', '$switch', '$on_off', '$up_down', '$color', '$value', '$artist', '$song']\n"
     ]
    }
   ],
   "source": [
    "output_tokens = [child.key for child in parsed.children if child.type in ['phrase', 'variable']]\n",
    "output_tokens = ['EOS'] + output_tokens\n",
    "print(output_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting input and target data for nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words_for_position(words, position):\n",
    "    if position is None:\n",
    "        return words\n",
    "    start, end, length = position\n",
    "    return words[start : end + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def relative_position(node, parent):\n",
    "    if parent.position is None:\n",
    "        return node.position\n",
    "    return node.position[0] - parent.position[0], node.position[1] - parent.position[0], node.position[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_for_node(flat, node):\n",
    "    words = [child.key for child in flat.children]\n",
    "    inputs = words_for_position(words, node.position)\n",
    "    keys = [child.key for child in node.children]\n",
    "    positions = [relative_position(child, node) for child in node.children]\n",
    "    return node.key, inputs, list(zip(keys, positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Set the volume high then also turn the volume high.\n",
      "( %\n",
      "    ( %sequence (0, 9, 10)\n",
      "        ( %setVolume (0, 3, 4)\n",
      "            ( $up_down (3, 3, 1) high ) )\n",
      "        ( %setVolume (6, 9, 4)\n",
      "            ( $up_down (9, 9, 1) high ) ) ) )\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('%sequence',\n",
       " ['set',\n",
       "  'the',\n",
       "  'volume',\n",
       "  'high',\n",
       "  'then',\n",
       "  'also',\n",
       "  'turn',\n",
       "  'the',\n",
       "  'volume',\n",
       "  'high'],\n",
       " [('%setVolume', (0, 3, 4)), ('%setVolume', (6, 9, 4))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed, walked_flat, walked_tree = generate_from_file('.', 'grammar.nlg')\n",
    "data_for_node(walked_flat, walked_tree.children[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tensors for input and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_tensor(tokens, source_tokens, append_eos=True):\n",
    "    indexes = []\n",
    "    for token in tokens:\n",
    "        indexes.append(source_tokens.index(token))\n",
    "    if append_eos:\n",
    "        indexes.append(0)\n",
    "    return torch.LongTensor(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1  0  0\n",
       " 0  0  0  0  1\n",
       "[torch.FloatTensor of size 2x5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranges_to_tensor(ranges, seq_len):\n",
    "    ranges_tensor = torch.zeros(len(ranges), seq_len)\n",
    "    for r in range(len(ranges)):\n",
    "        start, end, _ = ranges[r]\n",
    "        ranges_tensor[r, start:end+1] = 1\n",
    "    return ranges_tensor\n",
    "\n",
    "ranges_to_tensor([(0, 2, 3), (4, 4, 1)], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The core model is a regular seq2seq/encoder-decoder model with attention. The attention model is from [Luong et al.'s \"Effective Approaches to Attention-based Neural Machine Translation\"](https://arxiv.org/abs/1508.04025) including options for \"dot\", \"general\", and \"concat\" based attention energies.\n",
    "\n",
    "The encoder and decoder take one additional input `context` which represents the phrase parent we are currently operating on, e.g. `%setLightState`. At the top level node the context is always `%`.\n",
    "\n",
    "The last piece of the model is a form of [Pointer Network](https://arxiv.org/abs/1506.03134) which will be run over the input sequence (or encoder outputs?) for each decoded token, in order to pick out which parts of the input phrase correspond to that token. The inputs are the decoded token and encoder outputs; the outputs of are a 0 or 1 for each word in the sequence.\n",
    "\n",
    "Once the decoder and pointer have chosen tokens and alignments, the phrase tokens and corresponding \"pointed at\" sub-inputs are used as the context and inputs of the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=True)\n",
    "\n",
    "    def forward(self, context_input, word_inputs):\n",
    "        # TODO: Incorporate context input\n",
    "        seq_len = word_inputs.size(0)\n",
    "        batch_size = word_inputs.size(1)\n",
    "        embedded = self.embedding(word_inputs.view(seq_len * batch_size, -1)) # Process seq x batch at once\n",
    "        output = embedded.view(seq_len, batch_size, -1) # Resize back to seq x batch for RNN\n",
    "        \n",
    "        outputs, hidden = self.gru(output)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DotAttn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DotAttn, self).__init__()\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
    "        if USE_CUDA: attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = hidden.dot(encoder_outputs[i])\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        self.attn = DotAttn()\n",
    "    \n",
    "    def forward(self, context_input, word_input, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        \n",
    "        # Combine context and embedded word, through RNN\n",
    "        rnn_input = torch.cat((context_input.unsqueeze(0), word_embedded), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pointer network is a recurrent neural network with an embedding, a single-layer GRU, and linear output layer with a sigmoid transformation. The hidden state is initialized with the output of the embedding layer, given the context token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Pointer(nn.Module):\n",
    "    def __init__(self, context_size, hidden_size):\n",
    "        super(Pointer, self).__init__()\n",
    "        \n",
    "        self.context_size = context_size # Context tokens (from output vocabulary)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(context_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, bidirectional=True)\n",
    "        self.out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, context, hidden, encoder_outputs):\n",
    "#         print('token_input', token_input.size())\n",
    "#         hidden = self.embedding(token_input).unsqueeze(0)\n",
    "#         print('encoder_outputs', encoder_outputs.size())\n",
    "        outputs, hidden = self.gru(encoder_outputs, hidden.repeat(2, 1, 1))\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:] # Sum bidirectional outputs\n",
    "        outputs = self.out(outputs.squeeze(1))\n",
    "        outputs = F.sigmoid(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn the whole thing into one model (thereby allowing it to be optimized with one optimizer) by combining the Encoder, Decoder, and Pointer networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RARNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(RARNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        \n",
    "        self.encoder = Encoder(input_size, hidden_size)\n",
    "        self.decoder = Decoder(hidden_size, output_size)\n",
    "        self.pointer = Pointer(output_size, hidden_size)\n",
    "\n",
    "    def forward(self, context_input, word_inputs, word_targets=None):\n",
    "        context_embedded = self.embedding(context_input)\n",
    "        \n",
    "        input_len = word_inputs.size(0)\n",
    "        target_len = word_targets.size(0) if word_targets is not None else 15\n",
    "        \n",
    "        encoder_outputs, encoder_hidden = self.encoder(context_embedded, word_inputs)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = Variable(torch.LongTensor([0])) # EOS/SOS token\n",
    "\n",
    "        # Variables to store outputs\n",
    "        decoder_attns = Variable(torch.zeros(target_len, 1, input_len))\n",
    "        decoder_outputs = Variable(torch.zeros(target_len, output_size))\n",
    "        pointer_outputs = Variable(torch.zeros(target_len - 1, input_len)) # Pointer never runs on EOS\n",
    "        \n",
    "        for i in range(target_len):\n",
    "#             print('\\n[decoder %d]' % i)\n",
    "            decoder_output, decoder_hidden, decoder_attn = self.decoder(context_embedded, decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            decoder_outputs[i] = decoder_output\n",
    "    \n",
    "            if word_targets is not None: # Teacher forcing with known targets\n",
    "                decoder_input = word_targets[i]\n",
    "\n",
    "                if i < target_len - 1:\n",
    "                    pointer_output = self.pointer(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                    pointer_outputs[i] = pointer_output\n",
    "\n",
    "            else: # Sample with last outputs\n",
    "                max_index = decoder_output.topk(1)[1].data[0][0]\n",
    "                decoder_input = Variable(torch.LongTensor([max_index]))\n",
    "\n",
    "                if max_index == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    pointer_output = self.pointer(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                    pointer_outputs[i] = pointer_output\n",
    "                    \n",
    "        if word_targets is None:\n",
    "            decoder_outputs = decoder_outputs[:i]\n",
    "            pointer_outputs = pointer_outputs[:i]\n",
    "\n",
    "        return decoder_outputs, pointer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The inputs to the network are the current phrase label, e.g. `%getLightState` and the string to parse, \"the living room light is on\". The outputs are the child node labels, `$light` and `$on_off` with a selection of words given by attention-like weights over the sequence, treated as boolean values given a threshold.\n",
    "\n",
    "Unlike usual seq2seq training, the attention weights have explicit targets to focus on the relevant sub-phrases and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_size = len(input_tokens)\n",
    "output_size = len(output_tokens)\n",
    "hidden_size = 100\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "rarnn = RARNN(input_size, output_size, hidden_size)\n",
    "optimizer = torch.optim.Adam(rarnn.parameters(), lr=learning_rate)\n",
    "\n",
    "decoder_criterion = nn.NLLLoss()\n",
    "pointer_criterion = nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(flat, node):\n",
    "    context, inputs, targets = data_for_node(flat, node)\n",
    "\n",
    "    # Turn inputs into tensors\n",
    "    context_var = tokens_to_tensor([context], output_tokens, False)\n",
    "    context_var = Variable(context_var)\n",
    "    inputs_var = tokens_to_tensor(inputs, input_tokens).view(-1, 1, 1) # seq x batch x size\n",
    "    inputs_var = Variable(inputs_var)\n",
    "    target_tokens = [target_token for target_token, _ in targets]\n",
    "    target_ranges = [target_range for _, target_range in targets]\n",
    "    target_tokens_var = tokens_to_tensor(target_tokens, output_tokens)\n",
    "    target_tokens_var = Variable(target_tokens_var)\n",
    "    target_ranges_var = ranges_to_tensor(target_ranges, len(inputs) + 1)\n",
    "    target_ranges_var = Variable(target_ranges_var)\n",
    " \n",
    "    # Run through model\n",
    "    decoder_outputs, pointer_outputs = rarnn(context_var, inputs_var, target_tokens_var)\n",
    "\n",
    "    # Loss calculation and backprop\n",
    "    optimizer.zero_grad()\n",
    "    decoder_loss = decoder_criterion(decoder_outputs, target_tokens_var)\n",
    "    pointer_loss = pointer_criterion(pointer_outputs, target_ranges_var)\n",
    "    total_loss = decoder_loss + pointer_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return total_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job 593eca79f8e1c2083c22aa97 at 2017-06-12 10:08:10\n",
      "[log] 0m 9s (50) 2.7572\n",
      "[log] 0m 17s (100) 2.1512\n",
      "[log] 0m 25s (150) 2.0117\n",
      "[log] 0m 33s (200) 0.6180\n",
      "[log] 0m 43s (250) 1.0153\n",
      "[log] 0m 52s (300) 0.5083\n",
      "[log] 1m 2s (350) 0.5139\n",
      "[log] 1m 10s (400) 0.6200\n",
      "[log] 1m 19s (450) 0.4578\n",
      "[log] 1m 27s (500) 0.3731\n",
      "[log] 1m 36s (550) 0.2003\n",
      "[log] 1m 46s (600) 0.1153\n",
      "[log] 1m 54s (650) 0.2042\n",
      "[log] 2m 2s (700) 0.3133\n",
      "[log] 2m 10s (750) 0.2027\n",
      "[log] 2m 18s (800) 0.1185\n",
      "[log] 2m 26s (850) 0.0464\n",
      "[log] 2m 34s (900) 0.0747\n",
      "[log] 2m 42s (950) 0.0544\n",
      "[log] 2m 51s (1000) 0.0794\n",
      "[log] 2m 59s (1050) 0.0877\n",
      "[log] 3m 7s (1100) 0.4462\n",
      "[log] 3m 15s (1150) 0.6375\n",
      "[log] 3m 25s (1200) 0.2779\n",
      "[log] 3m 33s (1250) 0.0413\n",
      "[log] 3m 42s (1300) 0.0547\n",
      "[log] 3m 51s (1350) 0.0121\n",
      "[log] 4m 0s (1400) 0.0203\n",
      "[log] 4m 11s (1450) 0.0072\n",
      "[log] 4m 19s (1500) 0.4386\n",
      "[log] 4m 27s (1550) 0.0090\n",
      "[log] 4m 35s (1600) 0.3206\n",
      "[log] 4m 44s (1650) 0.0161\n",
      "[log] 4m 52s (1700) 0.0209\n",
      "[log] 5m 1s (1750) 0.0275\n",
      "[log] 5m 9s (1800) 0.0056\n",
      "[log] 5m 17s (1850) 0.0161\n",
      "[log] 5m 25s (1900) 0.0278\n",
      "[log] 5m 34s (1950) 0.1249\n"
     ]
    }
   ],
   "source": [
    "import sconce\n",
    "job = sconce.Job('rarnn')\n",
    "job.plot_every = 20\n",
    "job.log_every = 50\n",
    "\n",
    "n_epochs = 2000\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    walked_flat, walked_tree = walk_tree(parsed, parsed['%'], None)\n",
    "    def _train(node): return train(walked_flat, node)\n",
    "    ds = descend(walked_tree, _train)\n",
    "    d = sum(ds) / len(ds)\n",
    "    job.record(i, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/anaconda3/lib/python3.5/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['types', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(context, inputs, node=None):\n",
    "    if node == None:\n",
    "        node = Node('parsed')\n",
    "\n",
    "    print('(evaluate) %s %s' % (context, inputs))\n",
    "    context_var = tokens_to_tensor([context], output_tokens, False)\n",
    "    context_var = Variable(context_var)\n",
    "    inputs_var = tokens_to_tensor(inputs, input_tokens).view(-1, 1, 1) # seq x batch x size\n",
    "    inputs_var = Variable(inputs_var)\n",
    "    \n",
    "    decoder_outputs, pointer_outputs = rarnn(context_var, inputs_var)\n",
    "    fig = plt.figure(figsize=(len(inputs) / 2, 99))\n",
    "    sub = fig.add_subplot(111)\n",
    "    sub.matshow(pointer_outputs.data.squeeze(1).numpy(), vmin=0, vmax=1)\n",
    "    plt.show(); plt.close()\n",
    "    \n",
    "    next_contexts = []\n",
    "    next_inputs = []\n",
    "    \n",
    "    for i in range(len(decoder_outputs)):\n",
    "        max_index = decoder_outputs[i].topk(1)[1].data[0]\n",
    "        next_contexts.append(output_tokens[max_index])\n",
    "        p = pointer_outputs[i]\n",
    "        next_input = []\n",
    "        for j in range(len(p) - 1):\n",
    "            pj = p[j].data[0]\n",
    "            if pj > 0.5:\n",
    "                next_input.append(inputs[j])\n",
    "        next_inputs.append(next_input)\n",
    "\n",
    "    evaluated = list(zip(next_contexts, next_inputs))\n",
    "    print('evaluated', evaluated)\n",
    "    \n",
    "    for context, inputs in evaluated:\n",
    "        sub_node = Node(context)\n",
    "        node.add(sub_node)\n",
    "        if context[0] == '%':\n",
    "            evaluate(context, inputs, sub_node)\n",
    "        elif context[0] == '$':\n",
    "            sub_node.add(' '.join(inputs))\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def untokenize(ss): return ' '.join(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_and_print(context, inputs):\n",
    "    evaluated = evaluate(context, inputs)\n",
    "    print(untokenize(inputs))\n",
    "    print(evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['turn', 'the', 'volume', 'up'] ( %\n",
      "    ( %setVolume (0, 3, 4)\n",
      "        ( $up_down (3, 3, 1) up ) ) )\n",
      "(evaluate) % ['turn', 'the', 'volume', 'up']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL0AAABGCAYAAACZgpXqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAABLxJREFUeJzt3U+IVWUcxvHvY4lTFgUZFrSIiKJQptKKKJUcSWkxUQRZ\nA0EtxP5AuOnPKmjRrqG/QhIhUi1aFNkiFZs2YSJZimG2KdHCJBUsTMHGX4tzjHGsybn3vu85+j4f\nOIs5zPV5vfeZc8+/+15FBGYlmdL0AMxyc+mtOC69Fcelt+K49FYcl96K49JbcVx6K45Lb8Vx6a04\nrS29pKck/STpqKTNkm7NlDtP0lpJv0g6IWkwU+4LkrZI+l3SfkkfS7ouR3adv1zSdkmH62WTpCW5\n8seM4/n6eR9OldHK0kt6CHgFeBG4GdgOrJc0I0P8dGAb8CSQ88akecAbwO3AImAqsEHSBZny9wLP\nAbcAc4AR4BNJN2TKp96wLaN6vdOJiNYtwGbgtTE/C/gZeDbzOE4Agw09BzPq/LsafB0OAo9lyroI\n+AFYCHwBDKfKat2WXtJUqi3N5yfXRfWsbATuaGpcDbiU6p3mUO5gSVMkLQUuBL7KFPsW8GlEjKQO\nOj91QAdmAOcB+8et3w9cn384+UkS8CrwZUTszJg7i6rkfcAfwP0RsStD7lLgJmBu6ixoZ+kNVgI3\nAndmzt0F9AOXAA8CayTNT1l8SVdR/YEviojjqXLGamPpDwCjwMxx62cCv+YfTl6S3gTuBeZFxL6c\n2RHxF/Bj/eO3km4DngGeSBg7B7gc+KZ+h4PqnX6+pKeBafXubc+0bp++/mvfCgycXFc/GQPApqbG\nlUNd+PuAuyNiT9PjoerHtMQZG4HZVLs3/fXyNfAe0N/rwkM7t/QAw8BqSVuBLcAKqoOq1amDJU0H\nrqU6YwRwjaR+4FBE7E2YuxJ4GBgEjkg6+U53OCKOpcodk/8y8BmwB7gYGAIWAPekzI2II8Apxy2S\njgAHI+L7VKGtXKjOk+8GjlIdXM3NlLuA6lTh6Ljl3cS5/5Y5Cjya6f/9DtWuzVGq3cgNwMKGXvsR\nEp6yVB1iVozW7dObpebSW3FceiuOS2/FcemtOC69FSfpxSlJlwGLqc63J7/AYkXrA64G1kfEwYl+\nMfUV2cXA+4kzzMYaAj6Y6BdSl343wANU9wt3Yh2Q/TNrzu4qexXLGkg/AHwEdecmkrr0x6Aq/JUd\n/gN9XTy2W87uVDeP7jr9f3ejfSBrxXHprTguvRWn9aWf5eyisnOkt770s51dVHaO9NaX3qzXXHor\nTkelb2qeSbNemHTpG55n0qxrnWzpVwBvR8SaqCYBWg78CTze05GZJTKp0nueSTsXTHZLP9E8k1f0\nZERmifnsjRVnsndZdjTP5Dqqe+fGmkXTF0Hs7LUD+G7cujP/jNKkSh8Rx+up9gaAtXDKPJOv/9fj\nltDcbbJ2LprN6ZvMfcCqM3p0J/fTNzbPpFkvTLr0EfFhfU7+Jardmm3A4oj4rdeDM0uho09ORcRK\nqi8OMDvr+OyNFcelt+K49FYcl96K0/rS73B2Udk50ltf+vHX3Zx9bmfnSG996c16zaW34rj0VpzU\nc1n2QXVrZqeOUd1K1ARnd6qbR3ea/k/Lxt/Qe5qkX6kp6RE8VbflNRQRE07Vnbr0/lIGy+WMv5TB\nX55sxfGBrBXHpbfiuPRWHJfeiuPSW3FceiuOS2/F+RuxbA9UPFDeGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113a83828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('%setVolume', ['turn', 'the', 'volume', 'up'])]\n",
      "(evaluate) %setVolume ['turn', 'the', 'volume', 'up']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL0AAABGCAYAAACZgpXqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAABP9JREFUeJzt3U+oVGUcxvHvY4mWRUE3rGgREUWh3EorolRSSWlhFEGW\nENRC7A+Em/6sghbtkv5eSCJEqkWLIoNSMduEiWQpRtmmRCuTVLAwBdNfi3OU6zVv3jnzvmfG9/nA\ncLnDPfO8c+a5Z86cOfOOIgKzkoxrewBmubn0VhyX3orj0ltxXHorjktvxXHprTguvRXHpbfiuPRW\nnJ4tvaQnJf0s6ZCkjZJuyZQ7Q9IqSb9KOiZpQabc5yVtkvSnpD2SPpJ0bY7sOn+JpK2SDtSXDZLm\n58ofNo7n6vW+LFVGT5Ze0oPAy8ALwE3AVmCNpIEM8ZOALcATQM4Tk2YArwO3AXOB8cBaSedlyt8F\nPAvcDEwD1gMfS7o+Uz71hm0x1eOdTkT03AXYCLw67HcBvwDPZB7HMWBBS+tgoM6/s8XHYR/waKas\nC4AfgdnAF8CyVFk9t6WXNJ5qS/P58euiWivrgNvbGlcLLqZ6ptmfO1jSOEkLgfOBrzLFvgl8EhHr\nUwedmzqgAwPAOcCeEdfvAa7LP5z8JAl4BfgyIr7PmDuFquQTgb+A+yJie4bchcCNwPTUWdCbpTcY\nAm4A7sicux0YBC4CHgBWSpqZsviSrqT6B58bEUdS5QzXi6XfCxwFJo+4fjLwe/7h5CXpDeAeYEZE\n7M6ZHRH/AD/Vv34r6VbgaeDxhLHTgEuBb+pnOKie6WdKegqYUO/edk3P7dPX/+2bgTnHr6tXxhxg\nQ1vjyqEu/L3AXRGxs+3xUPVjQuKMdcBUqt2bwfryNfAuMNjtwkNvbukBlgErJG0GNgFLqV5UrUgd\nLGkScA3VESOAqyUNAvsjYlfC3CHgIWABcFDS8We6AxFxOFXusPyXgM+AncCFwCJgFnB3ytyIOAic\n9LpF0kFgX0T8kCq0Jy9Ux8l3AIeoXlxNz5Q7i+pQ4dERl3cS5/5X5lHgkUz3+22qXZtDVLuRa4HZ\nLT3260l4yFJ1iFkxem6f3iw1l96K49JbcVx6K45Lb8Vx6a04Sd+cknQJMI/qeHvyN1isaBOBq4A1\nEbFvtD9M/Y7sPOC9xBlmwy0C3h/tD1KXfkf1436qM4Y7sRrI/qm1LmQ3XbWfUp131pnFDHW8bNM1\nvpzFDZbuNH0v8CGc6NzppS59vUszAFze4U1MbLBsU02yx3ch+4qOl26yxpqv8VbT/3c32i9krTgu\nvRXHpbfi9EHppxSaPbW15DbvdY70Pih9ew9+u9mDrSW3ea9zpPdB6c26y6W34nRU+rbmmTTrhjGX\nvuV5Js0a62RLvxR4KyJWRjUJ0BLgb+Cxro7MLJExld7zTNrZYKxb+tHmmbysKyMyS8xHb6w4Yz3L\nssN5JldTnT033BTafhvE+tU24LsR1535Z5TGVPqIOFJPtTcHWAUnzTP52umXnE97pwfb2Wcqp24w\ndwPLz2jpTs6nb22eSbNuGHPpI+KD+pj8i1S7NVuAeRHxR7cHZ5ZCR5+cioghaPB5NLMW+eiNFcel\nt+K49FYcl96K0wel31ZodtovzR5Nm/c6R3oflH7kO2+lZLdXvTbvdY70Pii9WXe59FYcl96Kk3ou\ny/rUyr0NbuIw1clEbWiS3XTVHgZ+63jpJmus+RpvI/1Ex0aeznuKpF+pKelhPFW35bUoIkadqjt1\n6f2lDJbLGX8pg7882YrjF7JWHJfeiuPSW3FceiuOS2/FcemtOC69FedfeWcRXUv7FuIAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1142b45f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('$up_down', ['up'])]\n",
      "turn the volume up\n",
      "( parsed\n",
      "    ( %setVolume\n",
      "        ( $up_down up ) ) )\n"
     ]
    }
   ],
   "source": [
    "walked_flat, walked_tree = walk_tree(parsed, parsed['%'], None)\n",
    "inputs = [child.key for child in walked_flat.children]\n",
    "print(inputs, walked_tree)\n",
    "evaluate_and_print('%', inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(evaluate) % ['hey', 'maia', 'if', 'the', 'ethereum', 'price', 'is', 'less', 'than', '20', 'then', 'turn', 'the', 'living', 'room', 'light', 'on']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAABMCAYAAABzok+5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGWolSZLUPEOtJEmSmvd/8WVMspPeAOcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114791908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('%if', ['if', 'the', 'ethereum', 'price', 'is', 'less', 'than', '20', 'then', 'turn', 'the', 'living', 'room', 'light', 'on'])]\n",
      "(evaluate) %if ['if', 'the', 'ethereum', 'price', 'is', 'less', 'than', '20', 'then', 'turn', 'the', 'living', 'room', 'light', 'on']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAC4CAYAAACmRUvCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN7oSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1142b1860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('%getPrice', ['the', 'ethereum', 'price']), ('$operator', ['less', 'than']), ('$value', ['20']), ('%setLightState', ['turn', 'the', 'living', 'room', 'light', 'on'])]\n",
      "(evaluate) %getPrice ['the', 'ethereum', 'price']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAABECAYAAABj98zGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAABIdJREFUeJzt3F9oVnUcx/H3ZzpcShk0sMCLqCgKzf5H5CZltOhiYYj9\nGQQlhNlF6EXSRQQFQRdFUQyKDDHqYoRSN6VYFyUqgjQ1wptK1LDRFGbkDJ3fLs6zkKdN9/x2vuec\n59n3BQ9zZ/s9n99hH885z3mec2RmhJC3trInEFpTFCu4iGIFF1Gs4CKKFVxEsYKLKFZwEcUKLqJY\nwUUUK7ioZLEkvSjpN0mjkvZIuts5r0vSV5J+l3ReUq9nXi3zFUl7JZ2SNCRpq6QbnTPXSNovaaT2\n2CXpEY+syhVL0hPA28BrwO3AfmCbpE7H2HnAILAWKOrN0y7gfeBe4CGgHdgu6TLHzKPABuAO4E7g\nO+BLSTfnnmRmlXoAe4D3LvhewDHg5YLyzwO9Jax3Zy17acG5J4Bn837eSm2xJLWT/U/6dnyZZWu/\nA7ivrHkV5EqyreXJIsIktUl6EpgL7M77+Wfn/YTT1AnMAobqlg8BNxU/nWJIEvAusNPMfnbOWkRW\npA7gL2CFmR3KO6dqxZqp+oFbgPsLyDoELAHmAyuBzZK68y5X1Yo1DIwBC+qWLwD+KH46/iR9ADwK\ndJnZce88MzsH/Fr79kdJ9wAvAS/kmVOpYywzOwvsA5aPL6vtJpYDu8qal5daqR4DHjCzIyVNow2Y\nk/eTVm2LBfAOsEnSPmAvsI7sAHOTV6CkecANZK9AAa6TtAQ4aWZHnTL7gaeAXuBvSeNb6REzO+OU\n+SbwNXAEuBzoA5YBD+ceVvTL6im+BF4LHAZGyQ4073LOW0b2Un+s7vGJY+ZEeWPAM46ZH5PtBkfJ\nDi22Aw96ZKkWGEKuKnWMFVpHFCu4iGIFF1Gs4CKKFVxEsYIL1xOkkq4CesjOSbmc9AuF6wCuBbaZ\n2YnJfsn7zHsP8JlzRihHH/D5ZD/0Ltbh7Mt6YGHC8I3A6oZHPc/6hKzMN0DqZ3U/3bkjadw/G15l\nzltvJI0dXTqQNC59TYeBLfDf33Zi3sWq7f4WAtcnDJ+bNO6ahKRxHdMYP+u2W5PGaf4VyWPhh8Rx\n01lT4BKHNnHwHlxEsYKLKFZwUfFidReeuKjwRJi9ckUJqb5rGsWqs7jwRGhf9XgJqb5rWvFihWaV\nVKyiL4EPzafhYpV0CXxoMilbrHXAh2a22bJr0dYAp4Hncp1ZaGoNFWuGXwIfGtDoFutil8BfncuM\nQkso6LrCjWTv+12omzJOJ4RGHAR+qls2tU8/NVqsxEvgV5P2JnQo12L+f77rOPDRJUc2tCu0GXYJ\nfEiXsiss/BL40HwaLpaZDdTOWb1OtgscBHrM7M+8JxeaV9LBu5n1k93TKYQJxXuFwUUUK7iIYgUX\nFS/W94UnHiw8Ec4ObCkh1XdNo1h16s8zF+HcF1tLSPVd04oXKzSrKFZwEcUKLrw/3dCRfTmWOPw0\n8EvDo6Zzs/Qz0xg/NnggaZyNnEoemz7b1DUdHv9Hx8V+y/XmtpKeJm4K0qr6zGzSm4J4FytuY9R6\npnQbo7gdd3ARB+/BRRQruIhiBRdRrOAiihVcRLGCiyhWcPEvoSAfLzMkUI0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ad6780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('$asset', ['ethereum'])]\n",
      "(evaluate) %setLightState ['turn', 'the', 'living', 'room', 'light', 'on']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAABpCAYAAADC3G2JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116d24d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('$light', ['living', 'room', 'light']), ('$on_off', ['on'])]\n",
      "hey maia if the ethereum price is less than 20 then turn the living room light on\n",
      "( parsed\n",
      "    ( %if\n",
      "        ( %getPrice\n",
      "            ( $asset ethereum ) )\n",
      "        ( $operator less than )\n",
      "        ( $value 20 )\n",
      "        ( %setLightState\n",
      "            ( $light living room light )\n",
      "            ( $on_off on ) ) ) )\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_print('%', 'hey maia if the ethereum price is less than 20 then turn the living room light on'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(evaluate) % ['hey', 'maia', \"what's\", 'the', 'ethereum', 'price']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAABICAYAAAAOLLsaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1168af1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('%getPrice', ['ethereum', 'price'])]\n",
      "(evaluate) %getPrice ['ethereum', 'price']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG8AAABBCAYAAADfY/omAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAA6ZJREFUeJztnE+IVVUcxz/fShhzIyRYriKihSgSFiE1hEww4mICN6KB\ni1YxrdwEroL2RakM5CIk0IWLAhehkbsoEQRFEXdJZjr4BwzUgWn8tThvYnw5zju3c+67P+f3gbt4\n593z+55zv/fcd8655zyZGYFPnhl2AYLmhHmOCfMcE+Y5JsxzTJjnmDDPMWGeY8I8x4R5jumceZI+\nlvSbpAeSTkt6s3D8UUnHJV2T9FDSRMn4C3T2SToj6S9J05K+l/RaSY1OmSdpJ/A58CnwOnAeOClp\nTUGZVcA5YBKoObE7ChwA3gLeA1YAP0paWUzBzDpzAKeBrxZ8FvAH8EklvYfAREt1W9PTe6dUzM60\nPEkrgM3Aqfk0S7X+CdgyrHIVZDWppd8pFbAz5pHuzGeB6b70aeDF9otTDkkCvgR+NrNLpeI+VypQ\n8ESmgPXA2yWDdsm8W8AcsLYvfS1wo/3ilEHSQWA7MGpm10vG7sxj08xmgbPA2Hxa73EzBvwyrHL9\nH3rGvQ9sNbPfS8fvUssD+AI4LOkscAbYCzwPHC4lIGkV8CqpJwvwiqRNwB0zu1pQZwrYBUwA9yTN\nP1HumtlMEZFhDw8e06WeBK4AD4BfgTcKx3+X1GWf6zu+qTAM6deYA/aU0lBPKHBIZ37zgnzCPMeE\neY4J8xwT5jkmzHNM1UG6pBeAcdK4rczAdHkwArwMnDSz24udVHuGZRw4UlnjaeYD4OhiX9Y27wrA\nDtL7nkE5AWzLFDrEZGYOgB9Ic8a5/J15fm6NbgHfQe/6LUZt82YgGfdSRqaRzPMT67JzJKUm+WYb\n6OTXiCV+aqLD4pgwzzFhnmM6ad6G1pQ2tqRTp0aNzKu9MLatSwqbWtKpU6Ns81paGBsMQJOWtxf4\n2sy+NbPLwEfAfeDDoiULliTLvGWwMNYVuS3vqV0Y65FO9jaDwcidHmu0MPYEaYJoIRtos1fZZS4A\nF/vSBnsBk2Wemc321lSOAcfhkYWx+xfLt42GM3vLgo389za+DhxaMmeTienqC2ODwcg2z8yO9cZ0\nn5Eel+eAcTO7WbpwwZNp9ErIzKZIO1+CIRK9TceEeY7ppHkXWlM635JOnRp10rz+UU892rpN6tSo\nk+YFgxHmOSbMc0ztpX8jkCZEc5ghTRDl8Wd2jqTUJF/uus3cGv17xfqnhB+l8hbl3aQ/jomj2bF7\naNuaY69CYwbaqxB70h0THRbHhHmOCfMcE+Y5JsxzTJjnmDDPMf8Aon+2DEYQ8Q0AAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116dc3160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('$asset', ['ethereum'])]\n",
      "hey maia what's the ethereum price\n",
      "( parsed\n",
      "    ( %getPrice\n",
      "        ( $asset ethereum ) ) )\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_print('%', 'hey maia what\\'s the ethereum price'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(evaluate) % ['hey', 'maia', 'play', 'some', 'Skrillex', 'please', 'and', 'then', 'turn', 'the', 'office', 'light', 'off']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAABLCAYAAAA29C5dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZLUGYuGJEnqjEVDkiR1xqIhSZI6838SxvsoZXytBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c09320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('%sequence', ['play', 'some', 'Skrillex', 'please', 'and', 'then', 'turn', 'the', 'office', 'light', 'off'])]\n",
      "(evaluate) %sequence ['play', 'some', 'Skrillex', 'please', 'and', 'then', 'turn', 'the', 'office', 'light', 'off']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAABuCAYAAACqeCPXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c1a8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('%playMusic', ['play', 'some', 'Skrillex', 'please']), ('%setLightState', ['turn', 'the', 'office', 'light', 'off'])]\n",
      "(evaluate) %playMusic ['play', 'some', 'Skrillex', 'please']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL0AAABGCAYAAACZgpXqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAABQVJREFUeJzt3U+oVGUcxvHvY4m3LAq6YVGLiCgK5VpaEaWSSkqEUQRZ\nQlALsT8QbvqzClq0SypLKCJEqkWLIgtSMduEiWQpRtmmJBOTVLAwBdNfi3OU6zX/3DnzvmfG9/nA\nIHe4c5/3nXk8c+bMmXcUEZiVZEzbAzDLzaW34rj0VhyX3orj0ltxXHorjktvxXHprTguvRXHpbfi\n9GzpJT0t6VdJByVtkHRrptxpklZK2inpqKR5mXJflLRR0l+Sdkv6RNL1ObLr/EWStkjaX1/WS5qb\nK3/YOF6o7/clqTJ6svSSHgZeBV4Cbga2AKslDWaIHw9sBp4Ccp6YNA1YCtwOzAbGAmskXZApfwfw\nPHALMAVYB3wq6cZM+dQbtoVUj3c6EdFzF2AD8PqwnwX8DjyXeRxHgXkt3QeDdf5dLT4Oe4HHM2Vd\nBPwMzAS+Apakyuq5Lb2ksVRbmi+PXRfVvbIWuKOtcbXgUqpnmn25gyWNkTQfuBD4JlPsW8BnEbEu\nddD5qQM6MAicB+wecf1u4Ib8w8lPkoDXgK8j4seMuROpSj4A/A08EBHbMuTOByYDU1NnQW+W3mAZ\ncBNwZ+bcbcAQcAnwELBC0vSUxZd0NdV/8NkRcThVznC9WPo9wBFgwojrJwB/5B9OXpLeBO4FpkXE\nrpzZEfEv8Ev94/eSbgOeBZ5MGDsFuBz4rn6Gg+qZfrqkZ4Bx9e5t1/TcPn39v30TMOvYdfWdMQtY\n39a4cqgLfz9wd0T81vZ4qPoxLnHGWmAS1e7NUH35FngfGOp24aE3t/QAS4DlkjYBG4HFVC+qlqcO\nljQeuI7qiBHAtZKGgH0RsSNh7jLgEWAecEDSsWe6/RFxKFXusPxXgC+A34CLgQXADOCelLkRcQA4\n4XWLpAPA3oj4KVVoT16ojpNvBw5Svbiamil3BtWhwiMjLu8lzv2/zCPAY5nm/S7Vrs1Bqt3INcDM\nlh77dSQ8ZKk6xKwYPbdPb5aaS2/FcemtOC69Fcelt+K49FacpG9OSboMmEN1vD35GyxWtAHgGmB1\nROw93S+mfkd2DvBB4gyz4RYAH57uF1KXfnv1z4NUZwx3YhWQ/VNrjbMX8k5LyZUmJ8x8DtzX4PZL\nWdjg1p3OfA/wMRzv3KmlLn29SzMIXNnhnxhocNumOs9uOuKms27yGcMB4KoGt2828saP9xl3o/1C\n1orj0ltxXHorTh+UfmKR2W3OeqjF7Bwz74PSTyoyu81ZT24xO8fM+6D0Zt3l0ltxOip9W+tMmnXD\nqEvf8jqTZo11sqVfDLwdESuiWgRoEfAP8ERXR2aWyKhK73Um7Vww2i396daZvKIrIzJLzEdvrDij\nPcuyw3UmV1GdPTfcRNp9C8b611bghxHXnf1nlEZV+og4XC+1NwtYCSesM/nGqW85l/ZOD7ZzzyRO\n3mDugrP8DEMn59O3ts6kWTeMuvQR8VF9TP5lqt2azcCciPiz24MzS6GjT05FxDKqLw4w6zs+emPF\ncemtOC69Fcelt+L0Qem3Fpnd5qw3t5idY+Z9UPqR77yVkd3mrNN+R/2ZpJ95H5TerLtceiuOS2/F\nSb2WZX1q5Z4Gf+IQ1clEbeg8u+mIm866yQKuh4CdDW7fbOSdzvx4x0aeznuSpF+pKelRvFS35bUg\nIk67VHfq0vtLGSyXs/5SBn95shXHL2StOC69Fcelt+K49FYcl96K49JbcVx6K85/oNERZGqcTIcA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ccc0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('$artist', ['Skrillex', 'please'])]\n",
      "(evaluate) %setLightState ['turn', 'the', 'office', 'light', 'off']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOQAAABoCAYAAADhJVwuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAABstJREFUeJzt3VuIXeUZxvH/4wFHJ6WFpGowLRJsi5IwVlMPmFjaiJFe\npBSktebGeBFSLYo3rUIhRkQESbDVBupNNKiFIpbGiybFRi2iIdRDVDyUtkbjKZgEoqQVonm9WGvi\nZHIw+7C+9e7Zzw82w2xm7+ebNfPstdfaa61PEYGZ5XBc2wMwsy+4kGaJuJBmibiQZom4kGaJuJBm\nibiQZom4kGaJuJBmibiQZomkLqSk6yW9Ken/kjZL+l7B7AWS1kt6V9J+SYtLZdf5t0jaIukjSTsk\n/VnStwvmL5e0VdKe+vaMpCtK5R9mPDfXf4fVBTNX1JkTb682mZm2kJJ+BqwCVgDfBbYCGyXNKDSE\nUeBF4DqgjQN+FwD3ABcClwEnAn+TdHKh/O3Ar4HzgPOBTcBfJJ1dKP+A+oV4GdX/QGmvAKcBp9e3\n+Y2mRUTKG7AZ+O2E7wW8A/yqhbHsBxa3vDxm1OOY3+IYdgFLC2dOA94Afgg8AawumL0CeL7k75ty\nDSnpRKpX5b+P3xfVEnocuLitcbXsa1Rr6t2lgyUdJ+kq4BTg2cLxvwcei4hNhXPHfavebPmPpAcl\nfaPJsBOafPIezACOB3ZMun8H8J3yw2mXJAF3A09HRKPbMJNy51AVcAT4GPhJRLxeMP8q4FxgXqnM\nSTYD11CtoWcCtwL/kDQnIvY2EZi1kHawNcA5wCWFc18HxoCvAlcC6yRdWqKUkmZRvQhdFhH7ms47\nnIjYOOHbVyRtAd4CfgqsbSIzayF3Ap9RbUxPdBrwQfnhtEfSvcCPgAUR8X7J7Ij4FPhv/e0Lki4A\nbgR+USD+fODrwPP1OwSo3jVdKumXwEn1ZkwxEbFH0r+As5rKSLkNWb8iPgcsHL+v/qMsBJ5pa1yl\n1WX8MfCDiHi77fFQ/b+cVCjrcWAu1VvWsfr2T+BBYKx0GQEkTaMqY2MvjFnXkACrgfslPQdsAW6i\n2qlwf4lwSaNUC3/81Xm2pDFgd0RsL5C/Bvg5sBjYK2n83cKeiPikQP4dwF+Bt4GvAEuA7wOXN50N\nUG+jHbS9LGkvsCsiXisxBkl3AY9RvU09A1gJ7AP+2FRm2kJGxJ/qzxxvo3qr+iKwKCI+LDSEeVS7\n2aO+rarvfwC4tkD+8jr3yUn3LwXWFcg/lep3nQnsAV4CLm9xbyeU/zx4FvAwMB34EHgauCgidjUV\nqBbW/GZ2BCm3Ic2GlQtplogLaZaIC2mWiAtplogLaZZIo59DSpoOLAK2AY1/mG2W1AhwJrDxyz7D\nbPrAgEXAQw1nmA2KJVQHGhxR04XcVn25geqgh26tpTpApRv9OH3wEaqTHbqzjDt7St8AtHbtjD7l\n38eyBKNoK38n8Cgc6MORNV3I+m3qLGB2D08z2sPjp/WQO+5k4JtdP3pmj+kjfXiO9vO9FDiGzTbv\n1DFLxIU0S8SFNEtkQArZ7JX3vlxbl3SpzGk1vf38StujKJPvQh6TYtdnPqy5raa3n19pexRl8gek\nkGbDwYU0S8SFNEukq0K2OQmO2VTWcSETTIJjNmV1s4a8CfhDRKyrr2C9HPgfZa7EZjaldVRIT4Jj\n1qxO15BHmwTn9L6MyGyIeS+rWSKdnn7V5SQ4a6lOoZpoPu0fgWPWby9TTbo80bFfLKOjQkbEvnqu\njYXAejhoEpzfHfmRS+ntfEizQTGXQw+zex+475ge3c0Jyq1OgmM2lXVcyAST4JhNWV1dwiMi1lDN\n6mtmfeS9rGaJuJBmibiQZom4kGaJuJBmibiQZom4kGaJuJBmibiQZom4kGaJND37Ve3fwN4yUQmt\nZEXbQ2jd7axsNf83A/I38BrSLBEX0iwRF9IsERfSLBEX0iwRF9IsERfSLBEX0iwRF9IsERfSLJFu\npqNbIGm9pHcl7Ze0uImBmQ2jbtaQo1TXYr0OiP4Ox2y4dXOh5A3ABjgwjYCZ9Ym3Ic0ScSHNEnEh\nzRIpdILyBmBk0n1zOHTaLrNBV3B+yO5dAcwsE2XWqsLzQ0oaBc4CxvewzpY0BuyOiO2dPp+ZfaGb\nNeQ84AmqzyADWFXf/wBwbZ/GZTaUuvkc8im8M8isES6WWSIupFkiLqRZIi6kWSIupFkiA1LIl50/\n1Pmwte0BFFoGA1LIyYciOX+48jO8JJRZBgNSSLPh4EKaJeJCmiXS9Nke9TlXO3t8mk+ojphvi/N7\nzX+vDyPo7Tl6XX69LIMD//+Tz0E8hCKau06VpKuBhxoLMBssSyLi4aP9QNOFnA4sArbRyVmaZlPL\nCHAmsDEidh3tBxstpJl1xjt1zBJxIc0ScSHNEnEhzRJxIc0ScSHNEnEhzRL5HL3U8tEyylDNAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ce1518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated [('$light', ['office', 'light']), ('$on_off', ['off'])]\n",
      "hey maia play some Skrillex please and then turn the office light off\n",
      "( parsed\n",
      "    ( %sequence\n",
      "        ( %playMusic\n",
      "            ( $artist Skrillex please ) )\n",
      "        ( %setLightState\n",
      "            ( $light office light )\n",
      "            ( $on_off off ) ) ) )\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_print('%', 'hey maia play some Skrillex please and then turn the office light off'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
